{
  "questions": [
    {
      "questionId": "GOVERN-01-Q01",
      "subcatId": "GOVERN-01",
      "domainId": "GOVERN",
      "questionText": "Existe uma política formal documentada para uso e desenvolvimento de IA na organização?",
      "expectedEvidence": "Documento de política aprovado pela alta gestão com data de vigência, escopo de aplicação e responsáveis definidos",
      "imperativeChecks": "Verificar aprovação formal, data de última revisão, comunicação para stakeholders",
      "riskSummary": "Sem política formal, uso de IA é inconsistente e pode violar requisitos de segurança ou compliance",
      "frameworks": ["NIST AI RMF GOVERN 1.1", "ISO/IEC 42001 5.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-01-Q02",
      "subcatId": "GOVERN-01",
      "domainId": "GOVERN",
      "questionText": "A política de IA inclui requisitos específicos de segurança da informação?",
      "expectedEvidence": "Seções da política abordando confidencialidade, integridade, disponibilidade e requisitos de proteção de dados",
      "imperativeChecks": "Verificar alinhamento com política corporativa de segurança da informação",
      "riskSummary": "Política sem requisitos de segurança não protege adequadamente ativos de IA",
      "frameworks": ["ISO 27001 A.5.1", "NIST AI RMF GOVERN 1.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-01-Q03",
      "subcatId": "GOVERN-01",
      "domainId": "GOVERN",
      "questionText": "Existem procedimentos operacionais documentados para projetos de IA (SOPs)?",
      "expectedEvidence": "SOPs ou runbooks para desenvolvimento, deploy, operação e descontinuação de modelos",
      "imperativeChecks": "Verificar completude, atualização e evidência de aderência nos projetos ativos",
      "riskSummary": "Sem procedimentos padronizados, cada equipe opera de forma inconsistente",
      "frameworks": ["NIST AI RMF GOVERN 2.1", "ISO/IEC 42001 7.5"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-01-Q04",
      "subcatId": "GOVERN-01",
      "domainId": "GOVERN",
      "questionText": "As políticas de IA são revisadas periodicamente (ao menos anualmente)?",
      "expectedEvidence": "Registro de revisões com datas, responsáveis e mudanças realizadas; calendário de revisões futuras",
      "imperativeChecks": "Verificar data da última revisão, gatilhos para revisão extraordinária",
      "riskSummary": "Políticas desatualizadas não refletem novos riscos, tecnologias ou regulamentações",
      "frameworks": ["ISO 27001 5.3", "NIST AI RMF GOVERN 1.5"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-02-Q01",
      "subcatId": "GOVERN-02",
      "domainId": "GOVERN",
      "questionText": "Existe um comitê ou função responsável pela governança de IA na organização?",
      "expectedEvidence": "Organograma ou charter do comitê com membros, mandato e responsabilidades; atas de reuniões",
      "imperativeChecks": "Verificar frequência de reuniões, quórum e evidência de decisões tomadas",
      "riskSummary": "Sem governança formal, decisões de IA são descentralizadas e potencialmente conflitantes",
      "frameworks": ["NIST AI RMF GOVERN 2.2", "ISO/IEC 42001 5.3"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "GOVERN-02-Q02",
      "subcatId": "GOVERN-02",
      "domainId": "GOVERN",
      "questionText": "Os papéis e responsabilidades de segurança em projetos de IA estão claramente definidos?",
      "expectedEvidence": "Matriz RACI ou descrições de cargo incluindo responsabilidades de segurança para IA",
      "imperativeChecks": "Verificar se todos os projetos de IA têm responsável de segurança designado",
      "riskSummary": "Responsabilidades ambíguas levam a gaps de segurança onde ninguém assume accountability",
      "frameworks": ["ISO 27001 5.3", "NIST AI RMF GOVERN 2.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-02-Q03",
      "subcatId": "GOVERN-02",
      "domainId": "GOVERN",
      "questionText": "Existe processo de escalação definido para decisões críticas de IA?",
      "expectedEvidence": "Fluxograma ou procedimento de escalação com critérios, níveis e tempos de resposta",
      "imperativeChecks": "Verificar clareza dos critérios de escalação e evidência de uso do processo",
      "riskSummary": "Sem escalação clara, problemas críticos podem não ser tratados em tempo hábil",
      "frameworks": ["NIST AI RMF GOVERN 3.1", "ISO 27001 A.16.1"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "GOVERN-02-Q04",
      "subcatId": "GOVERN-02",
      "domainId": "GOVERN",
      "questionText": "Existe processo formal de comunicação de riscos de IA para stakeholders internos e externos?",
      "expectedEvidence": "Plano de comunicação de riscos com públicos-alvo, frequência, canais e templates; registros de comunicações realizadas",
      "imperativeChecks": "Verificar clareza das mensagens, adequação ao público e feedback recebido",
      "riskSummary": "Stakeholders não informados sobre riscos não podem tomar decisões adequadas ou preparar-se",
      "frameworks": ["ISO/IEC 23894 7.1", "ISO 31000 6.2", "NIST AI RMF GOVERN 4.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-03-Q01",
      "subcatId": "GOVERN-03",
      "domainId": "GOVERN",
      "questionText": "Foi realizado mapeamento das regulamentações aplicáveis a IA na organização?",
      "expectedEvidence": "Inventário de regulamentações com análise de aplicabilidade por tipo de sistema/dado",
      "imperativeChecks": "Verificar inclusão de LGPD, EU AI Act, regulamentações setoriais e internacionais aplicáveis",
      "riskSummary": "Desconhecimento regulatório resulta em violações não intencionais e multas",
      "frameworks": ["EU AI Act", "LGPD", "NIST AI RMF GOVERN 1.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-03-Q02",
      "subcatId": "GOVERN-03",
      "domainId": "GOVERN",
      "questionText": "Existe processo para monitorar mudanças regulatórias relevantes para IA?",
      "expectedEvidence": "Procedimento ou serviço de monitoramento regulatório com responsável designado",
      "imperativeChecks": "Verificar frequência de atualização e histórico de alertas recebidos",
      "riskSummary": "Novas regulamentações podem tornar práticas atuais não conformes sem aviso prévio",
      "frameworks": ["ISO 27001 4.2", "NIST AI RMF GOVERN 1.4"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-03-Q03",
      "subcatId": "GOVERN-03",
      "domainId": "GOVERN",
      "questionText": "Os sistemas de IA são classificados conforme níveis de risco do EU AI Act?",
      "expectedEvidence": "Classificação de sistemas por nível de risco (proibido, alto, limitado, mínimo) com justificativa",
      "imperativeChecks": "Verificar metodologia de classificação, revisão periódica e alinhamento com uso real",
      "riskSummary": "Classificação incorreta pode resultar em controles insuficientes ou não conformidade",
      "frameworks": ["EU AI Act Art. 6", "NIST AI RMF MAP 1.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-04-Q01",
      "subcatId": "GOVERN-04",
      "domainId": "GOVERN",
      "questionText": "Existe definição formal de apetite e tolerância a riscos de IA aprovada pela alta gestão?",
      "expectedEvidence": "Documento de risk appetite com níveis de tolerância por tipo de risco de IA, aprovado pelo board",
      "imperativeChecks": "Verificar aprovação executiva, comunicação e uso efetivo em decisões",
      "riskSummary": "Sem tolerância definida, decisões de risco são inconsistentes e subjetivas",
      "frameworks": ["NIST AI RMF GOVERN 1.3", "ISO 31000", "ISO/IEC 23894"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "GOVERN-04-Q02",
      "subcatId": "GOVERN-04",
      "domainId": "GOVERN",
      "questionText": "Existem critérios claros para priorização de riscos de IA?",
      "expectedEvidence": "Metodologia de priorização com critérios de impacto, probabilidade e urgência",
      "imperativeChecks": "Verificar uso consistente dos critérios em avaliações de risco",
      "riskSummary": "Sem critérios de priorização, recursos são alocados inadequadamente",
      "frameworks": ["NIST AI RMF GOVERN 1.4", "ISO 31000"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-04-Q03",
      "subcatId": "GOVERN-04",
      "domainId": "GOVERN",
      "questionText": "Os limiares de risco aceitável são revisados periodicamente?",
      "expectedEvidence": "Registros de revisão de tolerância a risco com frequência definida",
      "imperativeChecks": "Verificar gatilhos de revisão e ajustes realizados conforme contexto",
      "riskSummary": "Limiares desatualizados não refletem mudanças no ambiente de risco",
      "frameworks": ["NIST AI RMF GOVERN 1.3", "ISO 31000 6.4"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "GOVERN-04-Q04",
      "subcatId": "GOVERN-04",
      "domainId": "GOVERN",
      "questionText": "Existe registro formal de riscos de IA (Risk Register) centralizado e atualizado?",
      "expectedEvidence": "Risk register com identificação, descrição, impacto, probabilidade, owner, status de tratamento e data de atualização para cada risco",
      "imperativeChecks": "Verificar completude, atualização periódica e uso efetivo em decisões de gestão",
      "riskSummary": "Sem registro centralizado, riscos são geridos de forma inconsistente e sem visibilidade executiva",
      "frameworks": ["ISO/IEC 23894 7.2", "ISO 31000 6.7", "NIST AI RMF GOVERN 1.5"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-04-Q05",
      "subcatId": "GOVERN-04",
      "domainId": "GOVERN",
      "questionText": "Os riscos de IA estão integrados à gestão de riscos corporativa (ERM)?",
      "expectedEvidence": "Evidência de integração do risk register de IA com ERM corporativo; reporte consolidado para comitê de riscos",
      "imperativeChecks": "Verificar que riscos de IA são considerados no apetite de risco corporativo e reportados à alta gestão",
      "riskSummary": "Riscos de IA isolados do ERM não recebem visibilidade e recursos adequados",
      "frameworks": ["ISO/IEC 23894 7.3", "ISO 31000", "COSO ERM"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "GOVERN-05-Q01",
      "subcatId": "GOVERN-05",
      "domainId": "GOVERN",
      "questionText": "Existe processo formal para descomissionamento de sistemas de IA?",
      "expectedEvidence": "Procedimento de decommissioning com checklist, responsáveis e critérios de conclusão",
      "imperativeChecks": "Verificar execução em sistemas descontinuados recentemente",
      "riskSummary": "Sistemas não descomissionados adequadamente mantêm riscos residuais",
      "frameworks": ["NIST AI RMF GOVERN 1.7", "ISO 27001 A.8.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "GOVERN-05-Q02",
      "subcatId": "GOVERN-05",
      "domainId": "GOVERN",
      "questionText": "O processo de decommissioning inclui revogação de acessos e exclusão de dados?",
      "expectedEvidence": "Checklist com itens de revogação de acessos, exclusão de dados e confirmação",
      "imperativeChecks": "Verificar evidência de execução completa em descomissionamentos anteriores",
      "riskSummary": "Acessos e dados residuais mantêm exposição após desativação",
      "frameworks": ["NIST AI RMF GOVERN 1.7", "LGPD Art. 16"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "GOVERN-05-Q03",
      "subcatId": "GOVERN-05",
      "domainId": "GOVERN",
      "questionText": "Os modelos descontinuados são arquivados com documentação para auditoria futura?",
      "expectedEvidence": "Repositório de modelos arquivados com metadados, documentação e período de retenção",
      "imperativeChecks": "Verificar capacidade de recuperação para investigações e requisitos legais",
      "riskSummary": "Sem arquivo, investigações futuras ou requisitos legais não podem ser atendidos",
      "frameworks": ["NIST AI RMF GOVERN 4.3", "EU AI Act Art. 12"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-01-Q01",
      "subcatId": "MAP-01",
      "domainId": "MAP",
      "questionText": "Existe inventário completo de todos os sistemas de IA em uso ou desenvolvimento?",
      "expectedEvidence": "Catálogo de sistemas de IA com propósito, dados utilizados, responsáveis e status",
      "imperativeChecks": "Verificar completude do inventário, processo de atualização e cobertura de shadow AI",
      "riskSummary": "Sistemas de IA não inventariados são pontos cegos de segurança e compliance",
      "frameworks": ["NIST AI RMF MAP 1.1", "ISO/IEC 42001 6.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-01-Q02",
      "subcatId": "MAP-01",
      "domainId": "MAP",
      "questionText": "Os sistemas de IA são classificados por nível de criticidade e impacto?",
      "expectedEvidence": "Critérios de classificação de criticidade e mapeamento de cada sistema",
      "imperativeChecks": "Verificar consistência da classificação com a realidade operacional",
      "riskSummary": "Sem classificação de criticidade, recursos de segurança são mal alocados",
      "frameworks": ["NIST AI RMF MAP 1.2", "ISO 27001 A.8.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-01-Q03",
      "subcatId": "MAP-01",
      "domainId": "MAP",
      "questionText": "O inventário inclui casos de uso de IA generativa e LLMs?",
      "expectedEvidence": "Registro específico de aplicações de GenAI com propósito, dados e controles aplicados",
      "imperativeChecks": "Verificar cobertura de ferramentas comerciais de GenAI e modelos internos",
      "riskSummary": "GenAI não inventariada pode expor dados confidenciais ou violar políticas",
      "frameworks": ["OWASP LLM Top 10", "NIST AI RMF MAP 1.6"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-02-Q01",
      "subcatId": "MAP-02",
      "domainId": "MAP",
      "questionText": "Existe processo formal de avaliação de riscos específico para projetos de IA?",
      "expectedEvidence": "Metodologia de risk assessment para IA, templates e registros de avaliações realizadas",
      "imperativeChecks": "Verificar cobertura de projetos e integração com gestão de riscos corporativa",
      "riskSummary": "Riscos de IA não avaliados formalmente não podem ser tratados sistematicamente",
      "frameworks": ["NIST AI RMF MAP 1.1", "ISO 31000", "ISO/IEC 23894"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-02-Q02",
      "subcatId": "MAP-02",
      "domainId": "MAP",
      "questionText": "Os riscos de IA são categorizados e priorizados por impacto e probabilidade?",
      "expectedEvidence": "Matriz de riscos com classificação, registro de riscos atualizado e critérios de priorização",
      "imperativeChecks": "Verificar atualização periódica e uso efetivo para decisões de tratamento",
      "riskSummary": "Sem priorização baseada em risco, recursos de mitigação são alocados inadequadamente",
      "frameworks": ["NIST AI RMF MAP 1.2", "ISO 31000"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-02-Q03",
      "subcatId": "MAP-02",
      "domainId": "MAP",
      "questionText": "Os riscos identificados possuem planos de tratamento definidos com responsáveis?",
      "expectedEvidence": "Planos de tratamento com ações, responsáveis, prazos e status de implementação",
      "imperativeChecks": "Verificar execução dos planos e evidência de eficácia das mitigações",
      "riskSummary": "Riscos identificados sem tratamento permanecem como vulnerabilidades ativas",
      "frameworks": ["ISO 31000", "NIST AI RMF MANAGE 1.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-02-Q04",
      "subcatId": "MAP-02",
      "domainId": "MAP",
      "questionText": "Existe processo para identificar e monitorar riscos emergentes de IA?",
      "expectedEvidence": "Processo de horizon scanning para novos riscos de IA; acompanhamento de pesquisas, incidentes do setor e novas técnicas de ataque",
      "imperativeChecks": "Verificar fontes monitoradas, frequência de atualização e integração com avaliação de riscos",
      "riskSummary": "Riscos emergentes não identificados podem materializar-se antes de controles serem implementados",
      "frameworks": ["ISO/IEC 23894 8.2", "ISO 31000 6.3", "NIST AI RMF GOVERN 1.4"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-03-Q01",
      "subcatId": "MAP-03",
      "domainId": "MAP",
      "questionText": "São realizadas Avaliações de Impacto Algorítmico (AIA) para sistemas de alto risco?",
      "expectedEvidence": "Relatórios de AIA com metodologia, análise de impacto em direitos e ações de mitigação",
      "imperativeChecks": "Verificar completude, revisão por stakeholders afetados e atualização periódica",
      "riskSummary": "Sem AIA, impactos em direitos fundamentais podem não ser identificados antes do deploy",
      "frameworks": ["EU AI Act Art. 9", "NIST AI RMF MAP 1.5"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-03-Q02",
      "subcatId": "MAP-03",
      "domainId": "MAP",
      "questionText": "A AIA considera impactos em grupos vulneráveis ou protegidos?",
      "expectedEvidence": "Análise específica de impacto por grupo demográfico, medidas de proteção definidas",
      "imperativeChecks": "Verificar representatividade dos grupos analisados e consulta a especialistas",
      "riskSummary": "Impactos desproporcionais em grupos vulneráveis geram riscos legais e reputacionais",
      "frameworks": ["EU AI Act Art. 9", "NIST AI RMF MAP 1.5"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-04-Q01",
      "subcatId": "MAP-04",
      "domainId": "MAP",
      "questionText": "Os requisitos funcionais e não-funcionais de cada sistema de IA são documentados formalmente?",
      "expectedEvidence": "Especificação de requisitos com critérios de aceitação, restrições e dependências",
      "imperativeChecks": "Verificar completude, aprovação por stakeholders e rastreabilidade",
      "riskSummary": "Requisitos mal definidos levam a sistemas que não atendem às necessidades",
      "frameworks": ["NIST AI RMF MAP 1.3", "ISO/IEC 42001 6.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-04-Q02",
      "subcatId": "MAP-04",
      "domainId": "MAP",
      "questionText": "O contexto sociotécnico de uso do sistema de IA é analisado e documentado?",
      "expectedEvidence": "Análise de stakeholders, ambiente operacional, interações humanas e impactos sociais",
      "imperativeChecks": "Verificar consideração de fatores humanos e contexto organizacional",
      "riskSummary": "Sistemas desenvolvidos sem entender contexto falham em produção",
      "frameworks": ["NIST AI RMF MAP 1.2", "ISO/IEC 23894"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-04-Q03",
      "subcatId": "MAP-04",
      "domainId": "MAP",
      "questionText": "A análise de benefícios vs riscos é realizada antes da implementação de sistemas de IA?",
      "expectedEvidence": "Documentação de trade-offs, benefícios esperados, riscos identificados e decisão justificada",
      "imperativeChecks": "Verificar aprovação formal e reavaliação periódica do trade-off",
      "riskSummary": "Implementação sem análise de trade-off pode não justificar os riscos assumidos",
      "frameworks": ["NIST AI RMF MAP 1.4", "ISO 31000"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "MAP-05-Q01",
      "subcatId": "MAP-05",
      "domainId": "MAP",
      "questionText": "A escolha de algoritmos e arquiteturas de modelo é documentada com justificativa?",
      "expectedEvidence": "Documentação de alternativas consideradas, critérios de seleção e justificativa técnica",
      "imperativeChecks": "Verificar consideração de trade-offs de interpretabilidade, performance e fairness",
      "riskSummary": "Seleção de algoritmo sem critérios pode resultar em modelo inadequado",
      "frameworks": ["NIST AI RMF MAP 3.1", "ISO/IEC 42001"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-05-Q02",
      "subcatId": "MAP-05",
      "domainId": "MAP",
      "questionText": "As limitações conhecidas do modelo são documentadas e comunicadas aos usuários?",
      "expectedEvidence": "Documentação de limitações, edge cases, cenários de falha e instruções de uso",
      "imperativeChecks": "Verificar clareza, acessibilidade e compreensão pelos usuários",
      "riskSummary": "Uso do modelo fora de suas limitações causa resultados incorretos",
      "frameworks": ["NIST AI RMF MAP 3.2", "EU AI Act Art. 13"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-05-Q03",
      "subcatId": "MAP-05",
      "domainId": "MAP",
      "questionText": "As limitações de dados de treinamento e seus impactos no modelo são conhecidos?",
      "expectedEvidence": "Análise de representatividade, gaps de dados e impactos nas predições",
      "imperativeChecks": "Verificar documentação de vieses conhecidos e limitações de generalização",
      "riskSummary": "Limitações de dados não documentadas causam falhas inesperadas",
      "frameworks": ["NIST AI RMF MAP 3.2", "EU AI Act Art. 10"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-06-Q01",
      "subcatId": "MAP-06",
      "domainId": "MAP",
      "questionText": "As tarefas que o sistema de IA executa são mapeadas e documentadas claramente?",
      "expectedEvidence": "Inventário de tasks com inputs, outputs, decisões e ações resultantes",
      "imperativeChecks": "Verificar completude do mapeamento e alinhamento com uso real",
      "riskSummary": "Tasks não mapeadas podem ter impactos não previstos",
      "frameworks": ["NIST AI RMF MAP 4.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-06-Q02",
      "subcatId": "MAP-06",
      "domainId": "MAP",
      "questionText": "As limitações dos outputs do modelo são documentadas e comunicadas?",
      "expectedEvidence": "Documentação de incertezas, margem de erro, casos de baixa confiança",
      "imperativeChecks": "Verificar que usuários entendem limitações dos outputs",
      "riskSummary": "Outputs aceitos sem entender limitações causam decisões incorretas",
      "frameworks": ["NIST AI RMF MAP 4.2", "EU AI Act Art. 13"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-06-Q03",
      "subcatId": "MAP-06",
      "domainId": "MAP",
      "questionText": "O comportamento do sistema é monitorado no contexto pós-deploy para validar premissas?",
      "expectedEvidence": "Métricas de monitoramento pós-deploy, comparação com premissas, ajustes realizados",
      "imperativeChecks": "Verificar identificação de desvios e ações corretivas",
      "riskSummary": "Premissas de design podem não se confirmar em produção",
      "frameworks": ["NIST AI RMF MAP 4.3", "NIST AI RMF MEASURE 4.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MAP-07-Q01",
      "subcatId": "MAP-07",
      "domainId": "MAP",
      "questionText": "É realizada avaliação de gaps de trustworthiness antes da implantação?",
      "expectedEvidence": "Checklist de trustworthiness com avaliação de cada dimensão (valid, reliable, safe, secure, fair, transparent, accountable, privacy)",
      "imperativeChecks": "Verificar cobertura de todas as dimensões NIST e tratamento de gaps",
      "riskSummary": "Gaps de trustworthiness não identificados causam problemas em produção",
      "frameworks": ["NIST AI RMF MAP 5.1", "NIST AI RMF 3.1-3.7"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-07-Q02",
      "subcatId": "MAP-07",
      "domainId": "MAP",
      "questionText": "Os riscos residuais após mitigações são documentados e aceitos formalmente?",
      "expectedEvidence": "Registro de riscos residuais com justificativa, aprovação e monitoramento",
      "imperativeChecks": "Verificar aprovação por nível adequado e reavaliação periódica",
      "riskSummary": "Riscos residuais não aceitos formalmente não têm accountability clara",
      "frameworks": ["NIST AI RMF MAP 5.2", "ISO 31000"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "MAP-07-Q03",
      "subcatId": "MAP-07",
      "domainId": "MAP",
      "questionText": "Existe critério de go/no-go para deploy baseado em avaliação de trustworthiness?",
      "expectedEvidence": "Critérios de aprovação para deploy, gate de decisão documentado, registros de decisões",
      "imperativeChecks": "Verificar aplicação consistente e registros de sistemas não aprovados",
      "riskSummary": "Sem critérios claros, sistemas inadequados são implantados",
      "frameworks": ["NIST AI RMF MAP 5.3", "NIST AI RMF MANAGE 2.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-07-Q04",
      "subcatId": "MAP-07",
      "domainId": "MAP",
      "questionText": "É realizada modelagem de ameaças (Threat Modeling) específica para sistemas de IA?",
      "expectedEvidence": "Threat models documentados usando STRIDE, MITRE ATLAS ou metodologia similar; diagramas de fluxo de dados",
      "imperativeChecks": "Verificar cobertura de ameaças específicas de IA (poisoning, evasion, extraction, inference attacks)",
      "riskSummary": "Sem threat modeling, ameaças específicas de IA não são identificadas e mitigadas",
      "frameworks": ["CSA AI Security", "MITRE ATLAS", "NIST AI RMF MAP 1.5"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MAP-07-Q05",
      "subcatId": "MAP-07",
      "domainId": "MAP",
      "questionText": "São realizados testes de segurança específicos para IA (adversarial testing, red teaming)?",
      "expectedEvidence": "Relatórios de adversarial testing, red team exercises para IA, testes de robustez",
      "imperativeChecks": "Verificar cobertura de ataques como evasion, extraction, backdoor detection",
      "riskSummary": "Modelos não testados contra ataques adversariais são vulneráveis em produção",
      "frameworks": ["CSA AI Security", "MITRE ATLAS", "NIST AI RMF MEASURE 2.7"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-01-Q01",
      "subcatId": "DATA-01",
      "domainId": "DATA",
      "questionText": "Existe esquema de classificação de dados aplicado a datasets utilizados em IA?",
      "expectedEvidence": "Política de classificação com níveis definidos e critérios; classificação aplicada aos datasets",
      "imperativeChecks": "Verificar aplicação em datasets de treinamento, validação e produção",
      "riskSummary": "Dados não classificados podem ser expostos ou tratados com controles inadequados",
      "frameworks": ["ISO 27001 A.8.2", "NIST AI RMF MAP 2.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-01-Q02",
      "subcatId": "DATA-01",
      "domainId": "DATA",
      "questionText": "Os datasets de treinamento são inventariados com metadados de origem e linhagem?",
      "expectedEvidence": "Catálogo de dados com origem, data de coleta, transformações aplicadas e uso autorizado",
      "imperativeChecks": "Verificar atualização do inventário e rastreabilidade end-to-end",
      "riskSummary": "Datasets sem linhagem dificultam auditoria, compliance e investigação de problemas",
      "frameworks": ["NIST AI RMF MAP 2.2", "ISO/IEC 42001 6.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-01-Q03",
      "subcatId": "DATA-01",
      "domainId": "DATA",
      "questionText": "Existe processo para identificar dados pessoais e sensíveis em datasets de IA?",
      "expectedEvidence": "Procedimento de data discovery com ferramentas utilizadas e periodicidade de execução",
      "imperativeChecks": "Verificar execução em novos datasets e cobertura de dados não estruturados",
      "riskSummary": "Dados pessoais não identificados podem violar LGPD/GDPR e expor titulares",
      "frameworks": ["LGPD Art. 5", "GDPR Art. 4", "NIST Privacy Framework"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q01",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe base legal documentada para tratamento de dados pessoais em sistemas de IA?",
      "expectedEvidence": "Registro de bases legais por finalidade de tratamento, alinhado com ROPA",
      "imperativeChecks": "Verificar adequação da base legal e documentação para cada uso de dados pessoais",
      "riskSummary": "Tratamento sem base legal válida é violação de privacidade sujeita a sanções",
      "frameworks": ["LGPD Art. 7", "GDPR Art. 6", "NIST Privacy Framework"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q02",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Os titulares são informados sobre o uso de seus dados em sistemas de IA?",
      "expectedEvidence": "Avisos de privacidade mencionando uso de IA, finalidades e direitos dos titulares",
      "imperativeChecks": "Verificar clareza, acessibilidade e atualização das informações fornecidas",
      "riskSummary": "Falta de transparência viola direitos dos titulares e requisitos regulatórios",
      "frameworks": ["LGPD Art. 9", "GDPR Art. 13-14", "EU AI Act Art. 52"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q03",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe processo para atender direitos de titulares relacionados a IA (acesso, explicação, revisão)?",
      "expectedEvidence": "Procedimento documentado, canal de atendimento e SLA; capacidade técnica de atendimento",
      "imperativeChecks": "Verificar capacidade de identificar, explicar e excluir dados de modelos de IA",
      "riskSummary": "Incapacidade de atender direitos gera sanções regulatórias e erosão de confiança",
      "frameworks": ["LGPD Art. 18, 20", "GDPR Art. 15-22"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q04",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "O tratamento de dados sensíveis em sistemas de IA possui base legal específica conforme Art. 11 da LGPD?",
      "expectedEvidence": "Documentação de base legal para cada uso de dado sensível (saúde, biometria, etc.) em IA",
      "imperativeChecks": "Verificar se consentimento específico foi obtido ou se há outra base legal válida",
      "riskSummary": "Tratamento de dados sensíveis sem base legal adequada sujeita a sanções agravadas",
      "frameworks": ["LGPD Art. 11", "GDPR Art. 9"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q05",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe Registro das Operações de Tratamento (ROPA) incluindo sistemas de IA?",
      "expectedEvidence": "ROPA documentado com finalidades, bases legais, categorias de dados e compartilhamentos para cada sistema de IA",
      "imperativeChecks": "Verificar completude, atualização e inclusão de todos os sistemas de IA",
      "riskSummary": "Ausência de ROPA é violação direta da LGPD e dificulta demonstração de conformidade",
      "frameworks": ["LGPD Art. 37", "GDPR Art. 30"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q06",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Foi elaborado Relatório de Impacto à Proteção de Dados (RIPD/DPIA) para sistemas de IA de alto risco?",
      "expectedEvidence": "RIPD documentado com descrição do tratamento, riscos identificados, medidas de mitigação e parecer do DPO",
      "imperativeChecks": "Verificar cobertura de sistemas de IA que processam dados pessoais em larga escala ou dados sensíveis",
      "riskSummary": "ANPD pode exigir RIPD a qualquer momento; ausência demonstra negligência",
      "frameworks": ["LGPD Art. 38", "GDPR Art. 35", "EU AI Act Art. 9"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q07",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "O Encarregado (DPO) participa ativamente das decisões sobre uso de IA com dados pessoais?",
      "expectedEvidence": "Registros de consultas ao DPO, pareceres emitidos, participação em comitês de IA",
      "imperativeChecks": "Verificar envolvimento do DPO em novos projetos e avaliações de impacto",
      "riskSummary": "DPO não envolvido não pode cumprir seu papel de supervisão de conformidade",
      "frameworks": ["LGPD Art. 41", "GDPR Art. 37-39"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q08",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "O DPO possui conhecimento adequado sobre riscos específicos de IA e decisões automatizadas?",
      "expectedEvidence": "Capacitação do DPO em IA, participação em treinamentos específicos, certificações",
      "imperativeChecks": "Verificar capacidade do DPO de avaliar conformidade de sistemas de IA",
      "riskSummary": "DPO sem conhecimento de IA não consegue supervisionar conformidade adequadamente",
      "frameworks": ["LGPD Art. 41", "GDPR Art. 37"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q09",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe definição clara de responsabilidades entre controlador e operador para sistemas de IA?",
      "expectedEvidence": "Contratos com cláusulas de responsabilidade, definição de papéis, instruções documentadas",
      "imperativeChecks": "Verificar clareza de responsabilidades com fornecedores de IA e cloud providers",
      "riskSummary": "Responsabilidade não definida gera conflitos e exposição em caso de incidentes",
      "frameworks": ["LGPD Art. 42-43", "GDPR Art. 26, 28"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q10",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existem procedimentos para ressarcimento de danos causados por decisões automatizadas de IA?",
      "expectedEvidence": "Política de ressarcimento, processo de análise de reclamações, registros de casos",
      "imperativeChecks": "Verificar capacidade de identificar e remediar danos causados por IA",
      "riskSummary": "Ausência de processo de ressarcimento aumenta exposição a ações judiciais",
      "frameworks": ["LGPD Art. 42, 44, 45", "CDC"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-02-Q11",
      "subcatId": "DATA-02",
      "domainId": "DATA",
      "questionText": "Existe seguro ou provisão financeira para cobrir responsabilidade civil por danos de IA?",
      "expectedEvidence": "Apólice de seguro cyber/IA, provisões contábeis, análise de exposição financeira",
      "imperativeChecks": "Verificar adequação da cobertura aos riscos identificados",
      "riskSummary": "Danos significativos sem cobertura podem impactar financeiramente a organização",
      "frameworks": ["LGPD Art. 42, 44", "Gestão de Riscos"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "DATA-03-Q01",
      "subcatId": "DATA-03",
      "domainId": "DATA",
      "questionText": "Existem métricas de qualidade de dados definidas e monitoradas para datasets de IA?",
      "expectedEvidence": "KPIs de qualidade (completude, acurácia, consistência) com thresholds e monitoramento",
      "imperativeChecks": "Verificar ações corretivas para dados fora dos padrões de qualidade",
      "riskSummary": "Dados de baixa qualidade comprometem performance, fairness e confiabilidade do modelo",
      "frameworks": ["NIST AI RMF MAP 2.3", "ISO 8000"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-03-Q02",
      "subcatId": "DATA-03",
      "domainId": "DATA",
      "questionText": "Os dados de treinamento são validados quanto a representatividade e vieses?",
      "expectedEvidence": "Análises de distribuição demográfica, testes de viés e ações de balanceamento",
      "imperativeChecks": "Verificar metodologia, frequência de análise e tratamento de vieses identificados",
      "riskSummary": "Dados sub-representativos ou enviesados produzem modelos discriminatórios",
      "frameworks": ["NIST AI RMF MEASURE 2.6", "EU AI Act Art. 10"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-03-Q03",
      "subcatId": "DATA-03",
      "domainId": "DATA",
      "questionText": "Existem controles de integridade para prevenir alterações não autorizadas em datasets?",
      "expectedEvidence": "Controles de acesso a datasets, checksums, versionamento e logs de alterações",
      "imperativeChecks": "Verificar impossibilidade de alteração não rastreada e detecção de tampering",
      "riskSummary": "Datasets alterados maliciosamente podem envenenar modelos (data poisoning)",
      "frameworks": ["MITRE ATLAS AML.T0020", "NIST AI RMF MAP 2.4"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-04-Q01",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Existe política de retenção específica para dados utilizados em IA?",
      "expectedEvidence": "Política com prazos de retenção por tipo de dado e justificativa legal/negócio",
      "imperativeChecks": "Verificar alinhamento com LGPD e execução de exclusão nos prazos definidos",
      "riskSummary": "Retenção indefinida viola princípio de minimização e aumenta exposição",
      "frameworks": ["LGPD Art. 16", "GDPR Art. 5(1)(e)", "ISO 27001 A.8.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DATA-04-Q02",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Os dados obsoletos são descartados de forma segura e auditável?",
      "expectedEvidence": "Procedimento de descarte seguro, logs de exclusão e certificados quando aplicável",
      "imperativeChecks": "Verificar execução do descarte e impossibilidade de recuperação",
      "riskSummary": "Dados não descartados adequadamente podem ser expostos ou recuperados",
      "frameworks": ["ISO 27001 A.8.3", "NIST SP 800-88"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-04-Q03",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Existem controles de DLP (Data Leakage Prevention) para dados de treinamento de IA?",
      "expectedEvidence": "DLP configurado para datasets de IA, regras de bloqueio, logs de eventos",
      "imperativeChecks": "Verificar cobertura de canais de exfiltração (email, cloud, USB) para dados de IA",
      "riskSummary": "Dados de treinamento valiosos podem ser exfiltrados sem controles DLP",
      "frameworks": ["ISO 27001 A.8.12", "NIST SP 800-53 SC-7"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-04-Q04",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Existe monitoramento de exfiltração de dados através de outputs de modelos de IA?",
      "expectedEvidence": "Controles para detectar data leakage via inferência, logging de outputs sensíveis",
      "imperativeChecks": "Verificar detecção de tentativas de extração de dados via queries ao modelo",
      "riskSummary": "Modelos podem vazar dados de treinamento através de outputs (membership inference)",
      "frameworks": ["ISO 27001 A.8.12", "MITRE ATLAS AML.T0024", "OWASP LLM Top 10"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-04-Q05",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Dados enviados a APIs de IA externas são filtrados para remover informações sensíveis?",
      "expectedEvidence": "Pipeline de sanitização antes de envio a LLMs externos, logs de filtragem",
      "imperativeChecks": "Verificar que PII e dados confidenciais não são enviados a APIs de terceiros",
      "riskSummary": "Dados enviados a LLMs externos podem ser retidos ou expostos",
      "frameworks": ["ISO 27001 A.8.12", "OWASP LLM Top 10 LLM02", "LGPD Art. 46"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DATA-04-Q06",
      "subcatId": "DATA-04",
      "domainId": "DATA",
      "questionText": "Existe avaliação de riscos para transferências internacionais de dados utilizados em IA?",
      "expectedEvidence": "Mapeamento de fluxos transfronteiriços, análise de adequação de países, cláusulas contratuais padrão",
      "imperativeChecks": "Verificar conformidade com LGPD Art. 33, GDPR Cap. V e localização de provedores de IA",
      "riskSummary": "Transferências internacionais sem base legal adequada violam regulamentações de privacidade",
      "frameworks": ["CSA AI Security", "LGPD Art. 33", "GDPR Art. 44-49", "ISO 27701"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DEVELOP-01-Q01",
      "subcatId": "DEVELOP-01",
      "domainId": "DEVELOP",
      "questionText": "O ambiente de desenvolvimento de ML é segregado do ambiente de produção?",
      "expectedEvidence": "Diagrama de arquitetura com segregação clara, controles de acesso diferenciados",
      "imperativeChecks": "Verificar impossibilidade de acesso direto dev-prod e isolamento de dados",
      "riskSummary": "Ambientes misturados permitem comprometimento de produção via desenvolvimento",
      "frameworks": ["NIST AI RMF MANAGE 2.1", "ISO 27001 A.12.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-01-Q02",
      "subcatId": "DEVELOP-01",
      "domainId": "DEVELOP",
      "questionText": "Existem controles de proteção contra data poisoning no pipeline de treinamento?",
      "expectedEvidence": "Controles de integridade de dados, validações de entrada, detecção de anomalias",
      "imperativeChecks": "Verificar implementação e testes de eficácia dos controles",
      "riskSummary": "Data poisoning pode inserir backdoors ou degradar intencionalmente o modelo",
      "frameworks": ["OWASP LLM Top 10 LLM04:2025", "MITRE ATLAS AML.T0020", "NIST AI RMF MEASURE 2.5"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-01-Q03",
      "subcatId": "DEVELOP-01",
      "domainId": "DEVELOP",
      "questionText": "O processo de deploy de modelos inclui gates de aprovação de segurança?",
      "expectedEvidence": "Checklist de segurança para deploy, aprovações formais e registro de decisões",
      "imperativeChecks": "Verificar execução consistente do gate e critérios de bloqueio",
      "riskSummary": "Deploy sem validação de segurança coloca modelos vulneráveis em produção",
      "frameworks": ["NIST AI RMF MANAGE 2.2", "NIST SSDF PO.4"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-01-Q04",
      "subcatId": "DEVELOP-01",
      "domainId": "DEVELOP",
      "questionText": "Os ambientes de desenvolvimento de IA são seguros e isolados de produção?",
      "expectedEvidence": "Documentação de ambientes segregados, controles de acesso distintos, dados de teste anonimizados",
      "imperativeChecks": "Verificar isolamento de rede, segregação de credenciais e proteção de dados sensíveis em dev",
      "riskSummary": "Ambientes de desenvolvimento inseguros podem vazar dados ou ser usados como vetor de ataque",
      "frameworks": ["NIST SSDF PO.5", "ISO 27001 A.12.1.4", "NIST SP 800-53 SC-7"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-01-Q05",
      "subcatId": "DEVELOP-01",
      "domainId": "DEVELOP",
      "questionText": "O pipeline de build de modelos é protegido contra adulteração?",
      "expectedEvidence": "CI/CD com controles de acesso, logs imutáveis, assinatura de artefatos, SLSA Level 2+",
      "imperativeChecks": "Verificar integridade do pipeline, impossibilidade de builds não autorizados",
      "riskSummary": "Pipeline comprometido pode injetar código malicioso em todos os modelos produzidos",
      "frameworks": ["NIST SSDF PW.6", "SLSA", "NIST SP 800-53 SA-10"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-01-Q06",
      "subcatId": "DEVELOP-01",
      "domainId": "DEVELOP",
      "questionText": "Os modelos são deployados com configurações seguras por padrão?",
      "expectedEvidence": "Baseline de configuração segura documentado, validação automatizada antes do deploy",
      "imperativeChecks": "Verificar que configurações padrão seguem princípio de menor privilégio e defesa em profundidade",
      "riskSummary": "Configurações inseguras por padrão expõem modelos a ataques conhecidos",
      "frameworks": ["NIST SSDF PW.9", "CIS Benchmarks", "NIST SP 800-53 CM-6"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-02-Q01",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "O código de treinamento e inferência passa por revisão de segurança?",
      "expectedEvidence": "Processo de code review com checklist de segurança, ferramentas SAST integradas",
      "imperativeChecks": "Verificar cobertura, frequência e tratamento de findings",
      "riskSummary": "Código não revisado pode conter vulnerabilidades exploráveis",
      "frameworks": ["OWASP ML Top 10", "NIST AI RMF MANAGE 2.2", "NIST SSDF"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-02-Q02",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "As dependências do pipeline de ML são inventariadas e verificadas quanto a vulnerabilidades?",
      "expectedEvidence": "SBOM gerado, scans de dependências integrados ao CI/CD, processo de atualização",
      "imperativeChecks": "Verificar frequência de scans, cobertura e SLA de correção de vulnerabilidades",
      "riskSummary": "Dependências vulneráveis são vetores de ataque conhecidos e exploráveis",
      "frameworks": ["NIST SSDF", "SLSA", "OWASP Dependency Check"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-02-Q03",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "Existe processo de gestão de vulnerabilidades para componentes de IA?",
      "expectedEvidence": "Processo documentado com triagem, priorização, SLAs de correção e métricas",
      "imperativeChecks": "Verificar tempo médio de correção e cobertura de vulnerabilidades críticas",
      "riskSummary": "Vulnerabilidades não tratadas permanecem como superfície de ataque ativa",
      "frameworks": ["NIST CSF ID.RA", "ISO 27001 A.12.6"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-02-Q04",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "Existem funções e responsabilidades de segurança claramente definidas para o ciclo de desenvolvimento de IA?",
      "expectedEvidence": "Matriz RACI de segurança para desenvolvimento, security champions designados, job descriptions atualizadas",
      "imperativeChecks": "Verificar que cada fase do ciclo tem responsável de segurança e accountability clara",
      "riskSummary": "Sem responsabilidades claras, segurança é negligenciada entre equipes",
      "frameworks": ["NIST SSDF PO.2", "ISO 27001 5.3", "NIST AI RMF GOVERN 2.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DEVELOP-02-Q05",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "Existe mecanismo para verificar integridade de artefatos de ML (modelos, datasets, código)?",
      "expectedEvidence": "Assinaturas digitais, checksums, registros de proveniência (SLSA attestations)",
      "imperativeChecks": "Verificar capacidade de detectar alterações não autorizadas em qualquer artefato",
      "riskSummary": "Artefatos adulterados podem introduzir backdoors ou comportamento malicioso",
      "frameworks": ["NIST SSDF PS.2", "SLSA", "NIST SP 800-53 SI-7"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-02-Q06",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "Os requisitos de segurança são definidos formalmente no início de projetos de IA?",
      "expectedEvidence": "Template de requisitos de segurança, checklist de security by design, threat modeling inicial",
      "imperativeChecks": "Verificar incorporação de requisitos de segurança desde a concepção do projeto",
      "riskSummary": "Segurança adicionada posteriormente é mais cara e menos efetiva",
      "frameworks": ["NIST SSDF PW.1", "ISO 27001 A.14.1", "NIST AI RMF MAP 1.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DEVELOP-02-Q07",
      "subcatId": "DEVELOP-02",
      "domainId": "DEVELOP",
      "questionText": "Componentes de IA reutilizados são validados quanto à segurança antes da integração?",
      "expectedEvidence": "Processo de aprovação de componentes externos, checklist de segurança, registro de validações",
      "imperativeChecks": "Verificar cobertura de modelos pré-treinados, bibliotecas e datasets reutilizados",
      "riskSummary": "Componentes não validados podem introduzir vulnerabilidades ou backdoors",
      "frameworks": ["NIST SSDF PW.4", "SLSA", "NIST SP 800-53 SA-12"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-03-Q01",
      "subcatId": "DEVELOP-03",
      "domainId": "DEVELOP",
      "questionText": "Os modelos são versionados com controle formal de versões?",
      "expectedEvidence": "Sistema de versionamento (MLflow, DVC, etc.), histórico completo de versões",
      "imperativeChecks": "Verificar capacidade de recuperar qualquer versão anterior do modelo",
      "riskSummary": "Sem versionamento formal, rollback e investigação forense são impossíveis",
      "frameworks": ["NIST AI RMF GOVERN 4.1", "MLOps Best Practices"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-03-Q02",
      "subcatId": "DEVELOP-03",
      "domainId": "DEVELOP",
      "questionText": "Os experimentos de ML são registrados com metadados completos?",
      "expectedEvidence": "Logs de experimentos com hiperparâmetros, métricas, datasets e ambiente utilizado",
      "imperativeChecks": "Verificar completude dos registros e capacidade de reprodução",
      "riskSummary": "Experimentos não documentados não são reproduzíveis nem auditáveis",
      "frameworks": ["NIST AI RMF GOVERN 4.2", "ISO/IEC 42001 7.5"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-03-Q03",
      "subcatId": "DEVELOP-03",
      "domainId": "DEVELOP",
      "questionText": "Os modelos em produção podem ser rastreados até seus dados e código de origem?",
      "expectedEvidence": "Lineage tracking implementado, documentação de proveniência completa",
      "imperativeChecks": "Verificar capacidade de auditoria end-to-end de qualquer modelo ativo",
      "riskSummary": "Sem rastreabilidade, investigações de incidentes são impossíveis",
      "frameworks": ["NIST AI RMF GOVERN 4.3", "EU AI Act Art. 12"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-03-Q04",
      "subcatId": "DEVELOP-03",
      "domainId": "DEVELOP",
      "questionText": "Existe gestão formal de configuração para modelos de IA em produção?",
      "expectedEvidence": "Baseline de configuração documentado, controle de mudanças, registro de configurações ativas",
      "imperativeChecks": "Verificar capacidade de identificar configuração exata de qualquer modelo em produção",
      "riskSummary": "Sem configuration management, mudanças não autorizadas não são detectadas",
      "frameworks": ["ISO 27001 A.8.9", "NIST AI RMF GOVERN 4.1", "MLOps Best Practices"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-03-Q05",
      "subcatId": "DEVELOP-03",
      "domainId": "DEVELOP",
      "questionText": "Mudanças em configurações de modelos passam por processo de change management?",
      "expectedEvidence": "Processo de aprovação de mudanças, registros de alterações, rollback documentado",
      "imperativeChecks": "Verificar que mudanças em produção requerem aprovação e são rastreadas",
      "riskSummary": "Mudanças não controladas podem introduzir vulnerabilidades ou degradar performance",
      "frameworks": ["ISO 27001 A.8.9", "ISO 27001 A.8.32", "NIST CSF PR.IP"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DEVELOP-03-Q06",
      "subcatId": "DEVELOP-03",
      "domainId": "DEVELOP",
      "questionText": "Existe verificação periódica de conformidade das configurações de modelos com baseline?",
      "expectedEvidence": "Scans de configuration drift, alertas de desvios, processo de remediação",
      "imperativeChecks": "Verificar frequência de verificação e tratamento de desvios identificados",
      "riskSummary": "Configuration drift não detectado pode causar comportamento inesperado",
      "frameworks": ["ISO 27001 A.8.9", "NIST CSF DE.CM", "CIS Controls"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-01-Q01",
      "subcatId": "MEASURE-01",
      "domainId": "MEASURE",
      "questionText": "Os modelos são testados contra ataques adversariais antes do deploy?",
      "expectedEvidence": "Resultados de testes adversariais com metodologia, tipos de ataques e conclusões",
      "imperativeChecks": "Verificar cobertura de técnicas de ataque e frequência de testes",
      "riskSummary": "Modelos não testados são vulneráveis a evasão e manipulação de outputs",
      "frameworks": ["MITRE ATLAS AML.T0015", "NIST AI RMF MEASURE 2.7"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-01-Q02",
      "subcatId": "MEASURE-01",
      "domainId": "MEASURE",
      "questionText": "Existem defesas implementadas contra adversarial examples?",
      "expectedEvidence": "Técnicas de defesa (adversarial training, input validation, etc.) documentadas",
      "imperativeChecks": "Verificar eficácia das defesas através de testes e métricas",
      "riskSummary": "Sem defesas, atacantes podem manipular outputs do modelo sistematicamente",
      "frameworks": ["MITRE ATLAS", "NIST AI RMF MANAGE 2.3"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-01-Q03",
      "subcatId": "MEASURE-01",
      "domainId": "MEASURE",
      "questionText": "O modelo detecta e trata inputs anômalos ou fora de distribuição?",
      "expectedEvidence": "Mecanismos de OOD detection implementados, thresholds definidos, logs de rejeição",
      "imperativeChecks": "Verificar taxa de detecção, falsos positivos e ação tomada para inputs rejeitados",
      "riskSummary": "Inputs anômalos podem causar comportamento inesperado ou malicioso",
      "frameworks": ["NIST AI RMF MEASURE 2.8", "MITRE ATLAS AML.T0043"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-02-Q01",
      "subcatId": "MEASURE-02",
      "domainId": "MEASURE",
      "questionText": "Os modelos são avaliados quanto a vieses discriminatórios antes do deploy?",
      "expectedEvidence": "Relatórios de fairness testing com métricas de equidade por grupo demográfico",
      "imperativeChecks": "Verificar grupos avaliados, métricas utilizadas e critérios de aprovação",
      "riskSummary": "Vieses não detectados causam discriminação, danos e riscos legais",
      "frameworks": ["EU AI Act Art. 10", "NIST AI RMF MEASURE 2.6"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-02-Q02",
      "subcatId": "MEASURE-02",
      "domainId": "MEASURE",
      "questionText": "Existem ações corretivas definidas quando vieses são identificados?",
      "expectedEvidence": "Processo de remediação de vieses, critérios de aceitabilidade e histórico de ações",
      "imperativeChecks": "Verificar efetividade das correções e reavaliação após tratamento",
      "riskSummary": "Vieses identificados sem correção permanecem causando danos",
      "frameworks": ["NIST AI RMF MANAGE 1.3", "EU AI Act Art. 10"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-02-Q03",
      "subcatId": "MEASURE-02",
      "domainId": "MEASURE",
      "questionText": "O monitoramento de fairness é realizado continuamente em produção?",
      "expectedEvidence": "Dashboard de fairness em produção, alertas para desvios, relatórios periódicos",
      "imperativeChecks": "Verificar métricas monitoradas, thresholds de alerta e tempo de resposta",
      "riskSummary": "Vieses podem emergir em produção mesmo em modelos validados inicialmente",
      "frameworks": ["NIST AI RMF MEASURE 4.1", "EU AI Act Art. 9"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-03-Q01",
      "subcatId": "MEASURE-03",
      "domainId": "MEASURE",
      "questionText": "Os modelos de alto risco possuem documentação de explicabilidade (model cards)?",
      "expectedEvidence": "Model cards com propósito, limitações, métricas de performance e instruções de uso",
      "imperativeChecks": "Verificar completude, atualização e acessibilidade da documentação",
      "riskSummary": "Modelos sem documentação não podem ser auditados ou usados adequadamente",
      "frameworks": ["EU AI Act Art. 13", "NIST AI RMF MEASURE 2.9"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-03-Q02",
      "subcatId": "MEASURE-03",
      "domainId": "MEASURE",
      "questionText": "Técnicas de XAI são implementadas para explicar decisões importantes?",
      "expectedEvidence": "Implementação de SHAP, LIME ou similar; interface de explicação para usuários",
      "imperativeChecks": "Verificar qualidade das explicações, usabilidade e cobertura de casos críticos",
      "riskSummary": "Decisões sem explicação podem ser contestadas e não atendem requisitos regulatórios",
      "frameworks": ["NIST AI RMF MEASURE 2.10", "EU AI Act Art. 14"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-03-Q03",
      "subcatId": "MEASURE-03",
      "domainId": "MEASURE",
      "questionText": "Os usuários podem contestar e solicitar revisão de decisões automatizadas?",
      "expectedEvidence": "Canal de contestação, processo de revisão humana documentado, SLA de resposta",
      "imperativeChecks": "Verificar efetividade do processo, tempo de resposta e registro de contestações",
      "riskSummary": "Impossibilidade de contestar viola direitos dos afetados e regulamentações",
      "frameworks": ["LGPD Art. 20", "GDPR Art. 22", "EU AI Act Art. 14"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-04-Q01",
      "subcatId": "MEASURE-04",
      "domainId": "MEASURE",
      "questionText": "Existem métricas definidas para avaliar a performance do modelo em produção?",
      "expectedEvidence": "KPIs de performance (accuracy, precision, recall, F1) com thresholds e monitoramento",
      "imperativeChecks": "Verificar alinhamento com requisitos de negócio e atualização de baselines",
      "riskSummary": "Performance não medida pode degradar sem detecção",
      "frameworks": ["NIST AI RMF MEASURE 2.1", "ISO/IEC 42001"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-04-Q02",
      "subcatId": "MEASURE-04",
      "domainId": "MEASURE",
      "questionText": "A robustez do modelo é testada contra variações de dados de entrada?",
      "expectedEvidence": "Testes de robustez com perturbações, noise e edge cases documentados",
      "imperativeChecks": "Verificar cobertura de cenários e critérios de aceitação",
      "riskSummary": "Modelos não robustos falham com variações normais de entrada",
      "frameworks": ["NIST AI RMF MEASURE 2.2", "MITRE ATLAS"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-04-Q03",
      "subcatId": "MEASURE-04",
      "domainId": "MEASURE",
      "questionText": "Existem métricas de segurança específicas para sistemas de IA?",
      "expectedEvidence": "KPIs de segurança (taxa de ataques bloqueados, tempo de detecção, cobertura de controles)",
      "imperativeChecks": "Verificar monitoramento contínuo e ações para desvios",
      "riskSummary": "Sem métricas de segurança, eficácia dos controles não é medida",
      "frameworks": ["NIST AI RMF MEASURE 2.4", "NIST CSF"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-04-Q04",
      "subcatId": "MEASURE-04",
      "domainId": "MEASURE",
      "questionText": "A resiliência do sistema de IA é testada sob condições de stress?",
      "expectedEvidence": "Testes de stress, chaos engineering, recuperação de falhas documentados",
      "imperativeChecks": "Verificar comportamento sob carga extrema e recuperação",
      "riskSummary": "Sistemas não resilientes falham sob condições adversas",
      "frameworks": ["NIST AI RMF MEASURE 2.12", "NIST CSF PR.DS"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-04-Q05",
      "subcatId": "MEASURE-04",
      "domainId": "MEASURE",
      "questionText": "A confiabilidade do sistema (uptime, availability) é medida e atende SLAs?",
      "expectedEvidence": "Métricas de availability, SLAs definidos, histórico de cumprimento",
      "imperativeChecks": "Verificar aderência aos SLAs e ações para desvios",
      "riskSummary": "Baixa confiabilidade impacta operações dependentes do sistema",
      "frameworks": ["NIST AI RMF MEASURE 2.13", "ISO 27001 A.17"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-05-Q01",
      "subcatId": "MEASURE-05",
      "domainId": "MEASURE",
      "questionText": "Os sistemas de IA de alto risco passam por auditoria interna periódica?",
      "expectedEvidence": "Plano de auditoria, relatórios de auditoria, findings e remediações",
      "imperativeChecks": "Verificar frequência, cobertura e tratamento de findings",
      "riskSummary": "Sem auditoria interna, problemas sistêmicos não são detectados",
      "frameworks": ["NIST AI RMF MEASURE 3.1", "ISO 27001 9.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-05-Q02",
      "subcatId": "MEASURE-05",
      "domainId": "MEASURE",
      "questionText": "Existem auditorias externas ou revisões independentes de sistemas de IA críticos?",
      "expectedEvidence": "Relatórios de auditoria externa, certificações, avaliações de terceiros",
      "imperativeChecks": "Verificar independência do auditor e tratamento de recomendações",
      "riskSummary": "Revisão apenas interna pode não identificar problemas sistêmicos",
      "frameworks": ["NIST AI RMF MEASURE 3.2", "EU AI Act Art. 61"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-05-Q03",
      "subcatId": "MEASURE-05",
      "domainId": "MEASURE",
      "questionText": "Stakeholders afetados são consultados na avaliação de sistemas de IA?",
      "expectedEvidence": "Registros de consultas, feedback de usuários e afetados, incorporação de inputs",
      "imperativeChecks": "Verificar representatividade e uso efetivo do feedback",
      "riskSummary": "Avaliação sem input de afetados pode ignorar impactos reais",
      "frameworks": ["NIST AI RMF MEASURE 3.3", "EU AI Act Art. 9"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-06-Q01",
      "subcatId": "MEASURE-06",
      "domainId": "MEASURE",
      "questionText": "Existe monitoramento contínuo de drift de dados e modelo em produção?",
      "expectedEvidence": "Dashboard de drift monitoring, alertas configurados, ações de retreinamento",
      "imperativeChecks": "Verificar detecção de drift de distribuição e performance",
      "riskSummary": "Drift não detectado degrada performance silenciosamente",
      "frameworks": ["NIST AI RMF MEASURE 4.1", "MLOps Best Practices"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "MEASURE-06-Q02",
      "subcatId": "MEASURE-06",
      "domainId": "MEASURE",
      "questionText": "O impacto real do sistema em produção é rastreado e comparado com expectativas?",
      "expectedEvidence": "Métricas de impacto de negócio, comparação com business case, relatórios periódicos",
      "imperativeChecks": "Verificar alinhamento de resultados com objetivos definidos",
      "riskSummary": "Sistemas podem não entregar valor esperado sem tracking de impacto",
      "frameworks": ["NIST AI RMF MEASURE 4.2", "ISO/IEC 42001"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "MEASURE-06-Q03",
      "subcatId": "MEASURE-06",
      "domainId": "MEASURE",
      "questionText": "Existem mecanismos de feedback de usuários para melhoria contínua do modelo?",
      "expectedEvidence": "Canal de feedback, processo de incorporação, registros de melhorias implementadas",
      "imperativeChecks": "Verificar uso efetivo do feedback e ciclo de melhoria",
      "riskSummary": "Sem feedback, problemas do mundo real não são incorporados",
      "frameworks": ["NIST AI RMF MEASURE 4.3", "MLOps Best Practices"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q01",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "Os ambientes de IA utilizam imagens base hardened e atualizadas?",
      "expectedEvidence": "Baseline de hardening documentado, processo de atualização e evidência de conformidade",
      "imperativeChecks": "Verificar conformidade com CIS Benchmarks ou standard equivalente",
      "riskSummary": "Imagens não hardened contêm vulnerabilidades conhecidas exploráveis",
      "frameworks": ["CIS Benchmarks", "NIST SP 800-123", "CSA AI Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q04",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "As plataformas cloud utilizadas para IA estão configuradas seguindo as melhores práticas de segurança?",
      "expectedEvidence": "Avaliação de segurança de plataformas (AWS SageMaker, Azure ML, GCP Vertex), conformidade com benchmarks",
      "imperativeChecks": "Verificar configuração de IAM, encryption, logging e network controls nas plataformas de IA",
      "riskSummary": "Plataformas cloud mal configuradas expõem dados e modelos de IA",
      "frameworks": ["CSA AI Security", "CSA CCM", "CIS Cloud Benchmarks"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q05",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "A infraestrutura de GPU/TPU utilizada para treinamento e inferência está adequadamente protegida?",
      "expectedEvidence": "Controles de acesso a clusters de GPU, isolamento de workloads, monitoramento de uso",
      "imperativeChecks": "Verificar segmentação de recursos de compute, proteção de memória e logging de acesso",
      "riskSummary": "GPUs/TPUs não protegidas podem vazar dados de treinamento ou serem usadas para cryptomining",
      "frameworks": ["CSA AI Security", "NIST SP 800-53 SC-4", "CIS Kubernetes Benchmark"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q06",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "Existe segmentação de rede específica para workloads de IA (treinamento, inferência, dados)?",
      "expectedEvidence": "Diagrama de rede com segmentação, políticas de firewall, microsegmentação implementada",
      "imperativeChecks": "Verificar isolamento entre ambientes de treinamento, inferência e armazenamento de dados",
      "riskSummary": "Sem segmentação, comprometimento de um componente permite movimentação lateral",
      "frameworks": ["CSA AI Security", "NIST SP 800-53 SC-7", "Zero Trust Architecture"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q07",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "As aplicações de IA passam por processo de hardening antes do deploy em produção?",
      "expectedEvidence": "Checklist de hardening para aplicações de IA, desabilitação de features desnecessárias, configurações seguras",
      "imperativeChecks": "Verificar remoção de endpoints de debug, configuração de CORS, headers de segurança",
      "riskSummary": "Aplicações não hardened expõem superfície de ataque desnecessária",
      "frameworks": ["CSA AI Security", "OWASP ASVS", "CIS Application Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q02",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "Os modelos em produção executam em ambientes isolados (containers, VMs)?",
      "expectedEvidence": "Arquitetura de isolamento documentada, políticas de rede, segmentação",
      "imperativeChecks": "Verificar efetividade do isolamento e políticas de network segmentation",
      "riskSummary": "Falta de isolamento permite movimentação lateral após comprometimento",
      "frameworks": ["NIST SP 800-190", "CIS Docker Benchmark"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-01-Q03",
      "subcatId": "PROTECT-01",
      "domainId": "PROTECT",
      "questionText": "Existe processo de patch management para infraestrutura de IA?",
      "expectedEvidence": "Política de patching com SLAs por criticidade, cronograma e métricas de compliance",
      "imperativeChecks": "Verificar tempo médio de aplicação de patches críticos e cobertura",
      "riskSummary": "Sistemas desatualizados são alvos conhecidos de exploits automatizados",
      "frameworks": ["NIST CSF PR.IP-12", "ISO 27001 A.12.6"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-02-Q01",
      "subcatId": "PROTECT-02",
      "domainId": "PROTECT",
      "questionText": "O acesso a modelos e dados de IA requer autenticação forte (MFA)?",
      "expectedEvidence": "Configuração de MFA para acessos sensíveis, política de autenticação",
      "imperativeChecks": "Verificar cobertura de todos os pontos de acesso críticos",
      "riskSummary": "Autenticação fraca facilita acessos não autorizados via credenciais comprometidas",
      "frameworks": ["NIST SP 800-63B", "ISO 27001 A.9.4"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-02-Q02",
      "subcatId": "PROTECT-02",
      "domainId": "PROTECT",
      "questionText": "Existe revisão periódica de acessos a recursos de IA?",
      "expectedEvidence": "Processo de access review documentado, registros de revisões e ações corretivas",
      "imperativeChecks": "Verificar frequência, cobertura e remoção de acessos desnecessários",
      "riskSummary": "Acessos obsoletos ou excessivos aumentam superfície de ataque",
      "frameworks": ["ISO 27001 A.9.2.5", "NIST CSF PR.AC-1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PROTECT-02-Q03",
      "subcatId": "PROTECT-02",
      "domainId": "PROTECT",
      "questionText": "O princípio do menor privilégio é aplicado a contas de serviço de IA?",
      "expectedEvidence": "Documentação de permissões mínimas por conta, revisão periódica",
      "imperativeChecks": "Verificar ausência de permissões excessivas em contas de produção",
      "riskSummary": "Contas com privilégios excessivos amplificam impacto de comprometimento",
      "frameworks": ["NIST CSF PR.AC-4", "ISO 27001 A.9.2"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-03-Q01",
      "subcatId": "PROTECT-03",
      "domainId": "PROTECT",
      "questionText": "APIs de inferência possuem rate limiting e throttling configurados?",
      "expectedEvidence": "Configuração de rate limits por usuário/IP, alertas de violação, logs",
      "imperativeChecks": "Verificar limites adequados e tratamento de violações",
      "riskSummary": "Sem rate limiting, APIs são vulneráveis a DoS e extração de modelo",
      "frameworks": ["OWASP API Security Top 10", "NIST AI RMF MANAGE 3.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-03-Q02",
      "subcatId": "PROTECT-03",
      "domainId": "PROTECT",
      "questionText": "Existem controles de proteção contra extração de modelos?",
      "expectedEvidence": "Controles anti-extração (rate limiting, watermarking, query monitoring) implementados",
      "imperativeChecks": "Verificar eficácia dos controles através de testes e monitoramento",
      "riskSummary": "Modelos podem ser roubados via queries sistemáticas sem controles adequados",
      "frameworks": ["MITRE ATLAS AML.T0024", "NIST AI RMF MANAGE 3.2"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PROTECT-03-Q03",
      "subcatId": "PROTECT-03",
      "domainId": "PROTECT",
      "questionText": "Sistemas de LLM possuem guardrails contra prompt injection e jailbreak?",
      "expectedEvidence": "Controles de input/output filtering, detecção de prompts maliciosos implementados",
      "imperativeChecks": "Verificar eficácia através de testes com payloads conhecidos",
      "riskSummary": "LLMs sem guardrails podem ser manipulados para vazamento de dados ou bypass",
      "frameworks": ["OWASP LLM Top 10", "MITRE ATLAS AML.T0051"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-01-Q01",
      "subcatId": "DETECT-01",
      "domainId": "DETECT",
      "questionText": "Os logs de inferência são coletados com informações suficientes para auditoria?",
      "expectedEvidence": "Configuração de logging com campos críticos (input hash, output, user, timestamp)",
      "imperativeChecks": "Verificar completude dos logs e capacidade de reconstrução de decisões",
      "riskSummary": "Logs incompletos impossibilitam investigações forenses adequadas",
      "frameworks": ["ISO 27001 A.12.4", "NIST CSF DE.CM"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-01-Q02",
      "subcatId": "DETECT-01",
      "domainId": "DETECT",
      "questionText": "Os logs são protegidos contra adulteração e retidos pelo período adequado?",
      "expectedEvidence": "Controles de integridade de logs, período de retenção definido e enforcement",
      "imperativeChecks": "Verificar impossibilidade de alteração e conformidade com requisitos de retenção",
      "riskSummary": "Logs adulteráveis ou não retidos comprometem capacidade de investigação",
      "frameworks": ["ISO 27001 A.12.4", "NIST CSF PR.PT-1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-01-Q03",
      "subcatId": "DETECT-01",
      "domainId": "DETECT",
      "questionText": "Os logs de IA são integrados ao SIEM ou plataforma centralizada de monitoramento?",
      "expectedEvidence": "Integração com SIEM configurada, dashboards de monitoramento, alertas ativos",
      "imperativeChecks": "Verificar cobertura de logs críticos e tempo de ingestão",
      "riskSummary": "Logs isolados dificultam correlação e detecção de ataques sofisticados",
      "frameworks": ["NIST CSF DE.AE", "ISO 27001 A.12.4"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-02-Q01",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "Existe monitoramento de drift de modelo em produção?",
      "expectedEvidence": "Sistema de monitoramento de drift configurado, métricas e alertas definidos",
      "imperativeChecks": "Verificar métricas monitoradas, thresholds e ações de resposta",
      "riskSummary": "Drift não detectado degrada performance e pode indicar manipulação",
      "frameworks": ["NIST AI RMF MEASURE 4.1", "MLOps Best Practices"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-02-Q02",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "Existe detecção de anomalias no comportamento de modelos?",
      "expectedEvidence": "Sistema de detecção de anomalias implementado, baseline definido, alertas",
      "imperativeChecks": "Verificar tipos de anomalias detectadas e tempo de detecção",
      "riskSummary": "Comportamento anômalo pode indicar ataque ou degradação em curso",
      "frameworks": ["NIST AI RMF MEASURE 4.2", "MITRE ATLAS AML.T0048"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-02-Q03",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "Alertas de segurança de IA são tratados dentro de SLAs definidos?",
      "expectedEvidence": "SLAs de resposta por severidade, métricas de cumprimento, processo de escalação",
      "imperativeChecks": "Verificar tempo médio de resposta e taxa de alertas não tratados",
      "riskSummary": "Alertas não tratados permitem que ataques progridam sem resposta",
      "frameworks": ["NIST CSF RS.AN", "ISO 27001 A.16.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DETECT-02-Q04",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "A organização consome threat intelligence específica para ameaças de IA/ML?",
      "expectedEvidence": "Feeds de threat intel (MITRE ATLAS, CVEs de frameworks ML, alertas de fornecedores) integrados ao processo de segurança",
      "imperativeChecks": "Verificar fontes de intel utilizadas, frequência de atualização e uso em decisões de segurança",
      "riskSummary": "Sem threat intel de IA, a organização desconhece novas técnicas de ataque específicas",
      "frameworks": ["ISO 27001 A.5.7", "MITRE ATLAS", "NIST CSF ID.RA"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DETECT-02-Q05",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "Existe processo para análise e incorporação de threat intelligence de IA na gestão de riscos?",
      "expectedEvidence": "Processo documentado de triagem de intel, avaliação de aplicabilidade e atualização de controles",
      "imperativeChecks": "Verificar exemplos de ameaças incorporadas e ações tomadas",
      "riskSummary": "Intel não analisada não melhora postura de segurança",
      "frameworks": ["ISO 27001 A.5.7", "NIST AI RMF MAP 1.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "DETECT-02-Q06",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "A organização monitora vulnerabilidades em frameworks e bibliotecas de IA utilizados?",
      "expectedEvidence": "Alertas de CVEs para TensorFlow, PyTorch, transformers, etc.; processo de resposta",
      "imperativeChecks": "Verificar tempo de resposta a CVEs críticos em dependências de IA",
      "riskSummary": "Vulnerabilidades em frameworks de IA são rapidamente exploradas",
      "frameworks": ["ISO 27001 A.5.7", "NIST SSDF RV.1", "SLSA"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-02-Q07",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "Existe processo formal para avaliar, priorizar e remediar vulnerabilidades em sistemas de IA?",
      "expectedEvidence": "Processo documentado com critérios de priorização (CVSS, exploitability, impacto), SLAs de correção, métricas de MTTR",
      "imperativeChecks": "Verificar aderência aos SLAs e tratamento de vulnerabilidades críticas",
      "riskSummary": "Vulnerabilidades não remediadas em tempo hábil são exploradas por atacantes",
      "frameworks": ["NIST SSDF RV.2", "ISO 27001 A.12.6", "NIST SP 800-53 SI-2"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "DETECT-02-Q08",
      "subcatId": "DETECT-02",
      "domainId": "DETECT",
      "questionText": "Vulnerabilidades em IA são analisadas para identificar causa raiz e prevenir recorrência?",
      "expectedEvidence": "Relatórios de análise de causa raiz (RCA), ações preventivas documentadas, métricas de recorrência",
      "imperativeChecks": "Verificar que análise de causa raiz é realizada para vulnerabilidades críticas e melhorias são implementadas",
      "riskSummary": "Sem análise de causa raiz, mesmas vulnerabilidades reaparecem em novos desenvolvimentos",
      "frameworks": ["NIST SSDF RV.3", "ISO 27001 10.1", "NIST SP 800-53 SI-2"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "RESPOND-01-Q01",
      "subcatId": "RESPOND-01",
      "domainId": "RESPOND",
      "questionText": "Existe plano de resposta a incidentes específico para IA?",
      "expectedEvidence": "Playbook de IR para IA com cenários específicos (poisoning, evasion, extraction)",
      "imperativeChecks": "Verificar cobertura de cenários de IA e integração com IR corporativo",
      "riskSummary": "Sem playbook específico, resposta a incidentes de IA será improvisada",
      "frameworks": ["NIST CSF RS.RP", "ISO 27001 A.16", "NIST AI RMF MANAGE 4.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "RESPOND-01-Q02",
      "subcatId": "RESPOND-01",
      "domainId": "RESPOND",
      "questionText": "A equipe de resposta a incidentes é treinada em cenários de segurança de IA?",
      "expectedEvidence": "Registros de treinamento, exercícios de tabletop ou simulações realizadas",
      "imperativeChecks": "Verificar frequência de treinamentos e cobertura de competências de IA",
      "riskSummary": "Equipe não treinada em IA responderá inadequadamente a incidentes específicos",
      "frameworks": ["NIST CSF RS.CO", "ISO 27001 A.7.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "RESPOND-01-Q03",
      "subcatId": "RESPOND-01",
      "domainId": "RESPOND",
      "questionText": "Existe processo de post-mortem para incidentes de IA?",
      "expectedEvidence": "Template de post-mortem, registros de incidentes anteriores, lições aprendidas",
      "imperativeChecks": "Verificar implementação de melhorias identificadas e comunicação",
      "riskSummary": "Sem post-mortem estruturado, mesmos erros tendem a se repetir",
      "frameworks": ["NIST CSF RS.IM", "ISO 27001 A.16.1.6"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "RESPOND-01-Q04",
      "subcatId": "RESPOND-01",
      "domainId": "RESPOND",
      "questionText": "Existe processo de notificação à ANPD para incidentes de segurança envolvendo dados pessoais em IA?",
      "expectedEvidence": "Procedimento de notificação com critérios, templates, prazos e responsáveis definidos",
      "imperativeChecks": "Verificar alinhamento com prazo razoável exigido pela LGPD e capacidade de execução",
      "riskSummary": "Não notificação à ANPD é infração grave sujeita a sanções administrativas",
      "frameworks": ["LGPD Art. 48", "GDPR Art. 33"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "RESPOND-01-Q05",
      "subcatId": "RESPOND-01",
      "domainId": "RESPOND",
      "questionText": "O processo de notificação inclui comunicação aos titulares afetados por incidentes de IA?",
      "expectedEvidence": "Procedimento de comunicação a titulares, templates, critérios de quando comunicar",
      "imperativeChecks": "Verificar capacidade de identificar e contatar titulares afetados",
      "riskSummary": "Não comunicação aos titulares quando exigida agrava sanções e danos reputacionais",
      "frameworks": ["LGPD Art. 48", "GDPR Art. 34"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "RESPOND-01-Q06",
      "subcatId": "RESPOND-01",
      "domainId": "RESPOND",
      "questionText": "Incidentes envolvendo IA são classificados quanto ao impacto em dados pessoais?",
      "expectedEvidence": "Critérios de classificação de severidade considerando volume e sensibilidade de dados afetados",
      "imperativeChecks": "Verificar que classificação considera requisitos de notificação obrigatória",
      "riskSummary": "Classificação inadequada pode resultar em não notificação de incidentes graves",
      "frameworks": ["LGPD Art. 48", "NIST CSF RS.AN"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "RESPOND-02-Q01",
      "subcatId": "RESPOND-02",
      "domainId": "RESPOND",
      "questionText": "Existe backup regular de modelos e artefatos críticos de ML?",
      "expectedEvidence": "Política de backup, frequência, testes de restore bem-sucedidos",
      "imperativeChecks": "Verificar RTO/RPO definidos e capacidade comprovada de restore",
      "riskSummary": "Perda de modelos pode interromper operações críticas sem recuperação",
      "frameworks": ["ISO 27001 A.12.3", "NIST CSF PR.IP-4"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "RESPOND-02-Q02",
      "subcatId": "RESPOND-02",
      "domainId": "RESPOND",
      "questionText": "Existe plano de disaster recovery para sistemas de IA críticos?",
      "expectedEvidence": "Plano de DR documentado, cenários testados, RTO/RPO atendidos em teste",
      "imperativeChecks": "Verificar última data de teste e resultados obtidos",
      "riskSummary": "Sem DR testado, falhas podem ter impacto prolongado e irrecuperável",
      "frameworks": ["ISO 22301", "NIST CSF PR.IP-9"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "RESPOND-02-Q03",
      "subcatId": "RESPOND-02",
      "domainId": "RESPOND",
      "questionText": "Existe alocação formal de recursos (orçamento, pessoas) para tratamento de riscos de IA?",
      "expectedEvidence": "Orçamento dedicado, headcount alocado, plano de recursos por prioridade de risco",
      "imperativeChecks": "Verificar adequação de recursos às prioridades de risco identificadas",
      "riskSummary": "Sem recursos dedicados, tratamento de riscos não é executado efetivamente",
      "frameworks": ["NIST AI RMF MANAGE 1.2", "ISO 31000"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "RESPOND-02-Q04",
      "subcatId": "RESPOND-02",
      "domainId": "RESPOND",
      "questionText": "Existem planos de fallback para quando sistemas de IA falham ou se comportam inadequadamente?",
      "expectedEvidence": "Procedimentos de fallback documentados, processos manuais alternativos, testes realizados",
      "imperativeChecks": "Verificar capacidade de operação sem IA e tempo de ativação do fallback",
      "riskSummary": "Sem fallback, falhas de IA interrompem operações críticas",
      "frameworks": ["NIST AI RMF MANAGE 1.4", "ISO 22301"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "RESPOND-02-Q05",
      "subcatId": "RESPOND-02",
      "domainId": "RESPOND",
      "questionText": "Os planos de fallback são testados periodicamente para validar efetividade?",
      "expectedEvidence": "Registros de testes de fallback, resultados, melhorias implementadas",
      "imperativeChecks": "Verificar frequência de testes e capacidade operacional comprovada",
      "riskSummary": "Fallbacks não testados podem falhar quando necessários",
      "frameworks": ["NIST AI RMF MANAGE 1.4", "ISO 22301 8.5"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "SUPPLY-01-Q01",
      "subcatId": "SUPPLY-01",
      "domainId": "SUPPLY",
      "questionText": "Fornecedores de IA são avaliados quanto a práticas de segurança?",
      "expectedEvidence": "Questionários de due diligence, critérios de avaliação, registros de avaliações",
      "imperativeChecks": "Verificar cobertura de fornecedores críticos e frequência de reavaliação",
      "riskSummary": "Fornecedores sem avaliação podem introduzir vulnerabilidades desconhecidas",
      "frameworks": ["NIST AI RMF GOVERN 6.1", "ISO 27001 A.15"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "SUPPLY-01-Q02",
      "subcatId": "SUPPLY-01",
      "domainId": "SUPPLY",
      "questionText": "Contratos com fornecedores de IA incluem cláusulas de segurança adequadas?",
      "expectedEvidence": "Cláusulas contratuais de segurança, SLAs, direitos de auditoria, notificação",
      "imperativeChecks": "Verificar cobertura de confidencialidade, integridade e resposta a incidentes",
      "riskSummary": "Sem cláusulas contratuais, não há obrigação legal de fornecedores sobre segurança",
      "frameworks": ["ISO 27001 A.15.1", "NIST AI RMF GOVERN 6.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "SUPPLY-01-Q03",
      "subcatId": "SUPPLY-01",
      "domainId": "SUPPLY",
      "questionText": "Existe processo de offboarding seguro de fornecedores de IA?",
      "expectedEvidence": "Checklist de offboarding com revogação de acessos, devolução de dados, confirmação",
      "imperativeChecks": "Verificar execução do checklist e evidência de conclusão",
      "riskSummary": "Offboarding inadequado mantém acessos ativos de ex-fornecedores",
      "frameworks": ["ISO 27001 A.15.1", "NIST CSF PR.AC"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "SUPPLY-02-Q01",
      "subcatId": "SUPPLY-02",
      "domainId": "SUPPLY",
      "questionText": "Existe inventário de modelos pré-treinados e componentes de IA externos?",
      "expectedEvidence": "Inventário com origem, versão, licença, data de integração e uso aprovado",
      "imperativeChecks": "Verificar completude e processo de atualização do inventário",
      "riskSummary": "Componentes externos desconhecidos são pontos cegos de segurança",
      "frameworks": ["NIST AI RMF MAP 3.1", "SBOM practices", "CSA AI Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "SUPPLY-02-Q02",
      "subcatId": "SUPPLY-02",
      "domainId": "SUPPLY",
      "questionText": "Modelos pré-treinados são validados antes de uso em produção?",
      "expectedEvidence": "Processo de validação com testes de segurança, performance e viés",
      "imperativeChecks": "Verificar critérios de aprovação e registros de validação",
      "riskSummary": "Modelos não validados podem conter backdoors ou comportamento malicioso",
      "frameworks": ["SLSA", "NIST AI RMF MEASURE 2.5", "CSA AI Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "SUPPLY-02-Q03",
      "subcatId": "SUPPLY-02",
      "domainId": "SUPPLY",
      "questionText": "Existe monitoramento de vulnerabilidades em modelos e bibliotecas de IA externos?",
      "expectedEvidence": "Processo de monitoramento de CVEs e alertas de segurança para componentes de IA",
      "imperativeChecks": "Verificar cobertura de componentes críticos e tempo de resposta a alertas",
      "riskSummary": "Vulnerabilidades em componentes externos podem afetar sistemas dependentes",
      "frameworks": ["NIST SSDF", "SLSA", "CSA AI Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "SUPPLY-02-Q04",
      "subcatId": "SUPPLY-02",
      "domainId": "SUPPLY",
      "questionText": "Provedores de Models as a Service (MaaS) são avaliados quanto à segurança antes da contratação?",
      "expectedEvidence": "Due diligence de segurança para provedores como OpenAI, Anthropic, Google; avaliação de políticas de dados",
      "imperativeChecks": "Verificar políticas de retenção de dados, certificações de segurança e SLAs de disponibilidade",
      "riskSummary": "MaaS sem avaliação pode expor dados confidenciais ou violar requisitos de compliance",
      "frameworks": ["CSA AI Security", "ISO 27001 A.15", "NIST AI RMF GOVERN 6.1"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "SUPPLY-02-Q05",
      "subcatId": "SUPPLY-02",
      "domainId": "SUPPLY",
      "questionText": "Existe documentação de proveniência e integridade para todos os modelos de IA utilizados?",
      "expectedEvidence": "Model cards com origem, treinamento, limitações; assinaturas digitais; registros de proveniência",
      "imperativeChecks": "Verificar rastreabilidade completa desde origem até deploy para cada modelo",
      "riskSummary": "Modelos sem proveniência documentada não podem ser auditados ou verificados",
      "frameworks": ["CSA AI Security", "SLSA", "NIST AI RMF GOVERN 4.3"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "SUPPLY-02-Q06",
      "subcatId": "SUPPLY-02",
      "domainId": "SUPPLY",
      "questionText": "O modelo de responsabilidade compartilhada com provedores cloud de IA está claramente definido?",
      "expectedEvidence": "Documentação de responsabilidades cliente vs provedor, matriz RACI para segurança",
      "imperativeChecks": "Verificar clareza sobre quem é responsável por cada controle de segurança",
      "riskSummary": "Ambiguidade na responsabilidade compartilhada resulta em gaps de segurança",
      "frameworks": ["CSA AI Security", "CSA Shared Responsibility Model", "ISO 27017"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-01-Q01",
      "subcatId": "PEOPLE-01",
      "domainId": "PEOPLE",
      "questionText": "Existe programa de treinamento em segurança de IA para desenvolvedores?",
      "expectedEvidence": "Currículo de treinamento, registros de participação, avaliações de conhecimento",
      "imperativeChecks": "Verificar cobertura de desenvolvedores de ML e atualização do conteúdo",
      "riskSummary": "Desenvolvedores não treinados criam aplicações com vulnerabilidades",
      "frameworks": ["NIST AI RMF GOVERN 5.1", "ISO 27001 A.7.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-01-Q02",
      "subcatId": "PEOPLE-01",
      "domainId": "PEOPLE",
      "questionText": "Usuários de sistemas de IA recebem orientação sobre uso seguro e responsável?",
      "expectedEvidence": "Materiais de conscientização, guias de uso, termos de uso aceitos",
      "imperativeChecks": "Verificar clareza das orientações e evidência de comunicação",
      "riskSummary": "Usuários desinformados podem expor dados ou usar IA inadequadamente",
      "frameworks": ["NIST AI RMF GOVERN 5.2", "ISO 27001 A.7.2.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-01-Q03",
      "subcatId": "PEOPLE-01",
      "domainId": "PEOPLE",
      "questionText": "Existe conscientização específica sobre riscos de GenAI e LLMs?",
      "expectedEvidence": "Treinamentos sobre prompt injection, vazamento de dados, alucinações",
      "imperativeChecks": "Verificar atualização do conteúdo com novas técnicas de ataque",
      "riskSummary": "Uso ingênuo de GenAI expõe organização a vazamentos e desinformação",
      "frameworks": ["OWASP LLM Top 10", "MITRE ATLAS AML.T0051"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-02-Q01",
      "subcatId": "PEOPLE-02",
      "domainId": "PEOPLE",
      "questionText": "Existe código de ética ou princípios de uso responsável de IA?",
      "expectedEvidence": "Documento de ética aprovado, princípios definidos, mecanismos de enforcement",
      "imperativeChecks": "Verificar conhecimento pela organização e aplicação em decisões",
      "riskSummary": "Sem código de ética, decisões sobre uso de IA são inconsistentes",
      "frameworks": ["IEEE EAD", "NIST AI RMF GOVERN 3.2", "EU AI Act"],
      "ownershipType": "Executive"
    },
    {
      "questionId": "PEOPLE-02-Q02",
      "subcatId": "PEOPLE-02",
      "domainId": "PEOPLE",
      "questionText": "Existe canal seguro para reportar preocupações éticas sobre IA?",
      "expectedEvidence": "Canal de denúncias configurado, proteção a denunciantes, processo de investigação",
      "imperativeChecks": "Verificar acessibilidade do canal e tratamento de denúncias recebidas",
      "riskSummary": "Sem canal seguro, problemas éticos não são reportados ou tratados",
      "frameworks": ["EU AI Act Art. 62", "ISO 37002"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-03-Q01",
      "subcatId": "PEOPLE-03",
      "domainId": "PEOPLE",
      "questionText": "Sistemas de IA de alto risco permitem intervenção humana em tempo real?",
      "expectedEvidence": "Mecanismos de override implementados, logs de intervenções, treinamento de operadores",
      "imperativeChecks": "Verificar efetividade dos mecanismos e tempo de acionamento",
      "riskSummary": "Sem override, erros de IA não podem ser corrigidos antes de causar danos",
      "frameworks": ["EU AI Act Art. 14", "NIST AI RMF GOVERN 3.3"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "PEOPLE-03-Q02",
      "subcatId": "PEOPLE-03",
      "domainId": "PEOPLE",
      "questionText": "Existe processo de revisão humana para decisões automatizadas de alto impacto?",
      "expectedEvidence": "Critérios para revisão humana definidos, processo documentado, métricas",
      "imperativeChecks": "Verificar percentual de decisões revisadas e qualidade das revisões",
      "riskSummary": "Decisões críticas sem revisão humana podem causar danos significativos",
      "frameworks": ["LGPD Art. 20", "GDPR Art. 22", "EU AI Act Art. 14"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-03-Q03",
      "subcatId": "PEOPLE-03",
      "domainId": "PEOPLE",
      "questionText": "Os operadores humanos são qualificados para supervisionar sistemas de IA?",
      "expectedEvidence": "Programa de treinamento de operadores, competências definidas, certificação",
      "imperativeChecks": "Verificar cobertura de operadores e atualização do treinamento",
      "riskSummary": "Operadores não qualificados não detectam ou corrigem erros adequadamente",
      "frameworks": ["EU AI Act Art. 14", "NIST AI RMF GOVERN 5.3"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "PEOPLE-03-Q04",
      "subcatId": "PEOPLE-03",
      "domainId": "PEOPLE",
      "questionText": "Existe mecanismo de desligamento de emergência (kill switch) para IA crítica?",
      "expectedEvidence": "Procedimento de desligamento documentado, testes realizados, responsáveis definidos",
      "imperativeChecks": "Verificar tempo de acionamento e impacto controlado em sistemas dependentes",
      "riskSummary": "Sem kill switch, IA problemática não pode ser parada rapidamente",
      "frameworks": ["EU AI Act Art. 14", "NIST AI RMF MANAGE 4.2"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-01-Q01",
      "subcatId": "LLM-01",
      "domainId": "LLM",
      "questionText": "Existem controles para detectar e bloquear tentativas de prompt injection direta?",
      "expectedEvidence": "Filtros de input implementados, lista de padrões maliciosos, logs de bloqueio",
      "imperativeChecks": "Verificar eficácia com payloads de teste conhecidos (OWASP, red team)",
      "riskSummary": "Prompt injection direta pode forçar o modelo a ignorar instruções de sistema",
      "frameworks": ["OWASP LLM Top 10 LLM01:2025", "MITRE ATLAS AML.T0051"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-01-Q02",
      "subcatId": "LLM-01",
      "domainId": "LLM",
      "questionText": "O sistema está protegido contra prompt injection indireta via documentos ou fontes externas?",
      "expectedEvidence": "Sanitização de inputs de arquivos, URLs e bases de conhecimento; testes realizados",
      "imperativeChecks": "Verificar proteção em RAG, plugins e integração com documentos externos",
      "riskSummary": "Documentos maliciosos podem conter instruções que manipulam o modelo",
      "frameworks": ["OWASP LLM Top 10 LLM01:2025", "MITRE ATLAS AML.T0051.001"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-01-Q03",
      "subcatId": "LLM-01",
      "domainId": "LLM",
      "questionText": "As instruções de sistema (system prompt) estão protegidas contra vazamento?",
      "expectedEvidence": "Técnicas de proteção implementadas, testes de extração realizados",
      "imperativeChecks": "Testar com prompts conhecidos de extração de system prompt",
      "riskSummary": "Vazamento do system prompt expõe lógica de negócio e facilita ataques",
      "frameworks": ["OWASP LLM Top 10 LLM07:2025"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-02-Q01",
      "subcatId": "LLM-02",
      "domainId": "LLM",
      "questionText": "Existe filtragem de outputs para prevenir vazamento de dados pessoais (PII)?",
      "expectedEvidence": "Filtros de PII implementados, regex ou modelo de detecção, logs de bloqueio",
      "imperativeChecks": "Testar com prompts que tentam extrair dados pessoais do contexto",
      "riskSummary": "LLM pode inadvertidamente revelar PII presente no contexto ou treinamento",
      "frameworks": ["OWASP LLM Top 10 LLM02:2025", "LGPD Art. 46"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-02-Q02",
      "subcatId": "LLM-02",
      "domainId": "LLM",
      "questionText": "Dados confidenciais são mascarados ou removidos antes de serem enviados ao LLM?",
      "expectedEvidence": "Pipeline de pré-processamento com mascaramento, logs de sanitização",
      "imperativeChecks": "Verificar que dados sensíveis não chegam ao modelo ou API externa",
      "riskSummary": "Dados enviados a LLMs externos podem ser expostos ou usados em treinamento",
      "frameworks": ["OWASP LLM Top 10 LLM02:2025", "ISO 27001 A.8.11"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-02-Q03",
      "subcatId": "LLM-02",
      "domainId": "LLM",
      "questionText": "Os dados de treinamento ou fine-tuning foram auditados para remover informações sensíveis?",
      "expectedEvidence": "Relatório de auditoria de dados, processo de data scrubbing documentado",
      "imperativeChecks": "Verificar metodologia e cobertura da auditoria de dados sensíveis",
      "riskSummary": "Modelos podem memorizar e regurgitar dados sensíveis do treinamento",
      "frameworks": ["OWASP LLM Top 10 LLM02:2025", "NIST AI RMF MAP 2.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-03-Q01",
      "subcatId": "LLM-03",
      "domainId": "LLM",
      "questionText": "Modelos pré-treinados são verificados quanto a integridade e origem antes do uso?",
      "expectedEvidence": "Verificação de hash/assinatura, validação de fonte confiável, registro de proveniência",
      "imperativeChecks": "Verificar processo de validação e bloqueio de modelos não verificados",
      "riskSummary": "Modelos de fonte não confiável podem conter backdoors ou comportamento malicioso",
      "frameworks": ["OWASP LLM Top 10 LLM03:2025", "SLSA", "NIST SSDF PS.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-03-Q02",
      "subcatId": "LLM-03",
      "domainId": "LLM",
      "questionText": "Plugins e extensões de LLM passam por revisão de segurança antes da instalação?",
      "expectedEvidence": "Processo de aprovação de plugins, checklist de segurança, registro de aprovações",
      "imperativeChecks": "Verificar cobertura de todos os plugins em uso e critérios de aprovação",
      "riskSummary": "Plugins maliciosos podem executar código arbitrário ou exfiltrar dados",
      "frameworks": ["OWASP LLM Top 10 LLM03:2025", "NIST SSDF PO.3"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-03-Q03",
      "subcatId": "LLM-03",
      "domainId": "LLM",
      "questionText": "Existe monitoramento de vulnerabilidades para componentes de LLM (transformers, frameworks)?",
      "expectedEvidence": "Processo de monitoramento de CVEs, SBOM para componentes de IA, alertas configurados",
      "imperativeChecks": "Verificar tempo de resposta a novas vulnerabilidades em componentes críticos",
      "riskSummary": "Vulnerabilidades em frameworks de IA são rapidamente exploradas",
      "frameworks": ["OWASP LLM Top 10 LLM03:2025", "NIST SSDF RV.1"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-03-Q04",
      "subcatId": "LLM-03",
      "domainId": "LLM",
      "questionText": "Existem controles de segurança para sistemas de RAG e vector stores?",
      "expectedEvidence": "Controles de acesso a vector databases, validação de embeddings, proteção contra embedding injection",
      "imperativeChecks": "Verificar isolamento de namespaces, filtragem de metadados e proteção contra manipulação de vetores",
      "riskSummary": "Vector stores vulneráveis permitem injeção de conteúdo malicioso e bypass de controles de acesso",
      "frameworks": ["OWASP LLM Top 10 LLM08:2025", "MITRE ATLAS"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-04-Q01",
      "subcatId": "LLM-04",
      "domainId": "LLM",
      "questionText": "Os outputs do LLM são validados antes de serem executados em sistemas downstream?",
      "expectedEvidence": "Validação de outputs implementada, sanitização antes de execução, logs",
      "imperativeChecks": "Testar com outputs maliciosos (code injection, XSS, SQL injection)",
      "riskSummary": "Outputs não validados podem causar RCE, XSS ou injection em sistemas conectados",
      "frameworks": ["OWASP LLM Top 10 LLM05:2025"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-04-Q02",
      "subcatId": "LLM-04",
      "domainId": "LLM",
      "questionText": "Existe detecção e tratamento de alucinações (hallucinations) do modelo?",
      "expectedEvidence": "Mecanismos de fact-checking, grounding em dados confiáveis, disclaimers",
      "imperativeChecks": "Verificar taxa de detecção e tratamento dado a outputs não verificáveis",
      "riskSummary": "Alucinações podem causar decisões baseadas em informação falsa",
      "frameworks": ["OWASP LLM Top 10 LLM09:2025", "NIST AI RMF MEASURE 2.9"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-04-Q03",
      "subcatId": "LLM-04",
      "domainId": "LLM",
      "questionText": "Outputs que podem causar dano (bias, conteúdo tóxico) são filtrados?",
      "expectedEvidence": "Filtros de conteúdo implementados, classificadores de toxicidade, moderação",
      "imperativeChecks": "Testar com prompts que tentam gerar conteúdo prejudicial ou enviesado",
      "riskSummary": "Conteúdo tóxico ou enviesado causa danos reputacionais e legais",
      "frameworks": ["OWASP LLM Top 10 LLM09:2025", "EU AI Act Art. 10"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-05-Q01",
      "subcatId": "LLM-05",
      "domainId": "LLM",
      "questionText": "As permissões de ações que o LLM pode executar estão limitadas ao mínimo necessário?",
      "expectedEvidence": "Inventário de ações permitidas, princípio de menor privilégio aplicado",
      "imperativeChecks": "Verificar que LLM não tem acesso a ações destrutivas ou sensíveis sem aprovação",
      "riskSummary": "Agência excessiva permite que erros do modelo causem danos significativos",
      "frameworks": ["OWASP LLM Top 10 LLM06:2025", "NIST AI RMF GOVERN 3.3"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-05-Q02",
      "subcatId": "LLM-05",
      "domainId": "LLM",
      "questionText": "Ações de alto impacto executadas pelo LLM requerem confirmação humana?",
      "expectedEvidence": "Human-in-the-loop implementado para ações críticas, logs de aprovações",
      "imperativeChecks": "Verificar cobertura de ações críticas e efetividade do processo de aprovação",
      "riskSummary": "Ações irreversíveis sem confirmação podem causar danos não recuperáveis",
      "frameworks": ["OWASP LLM Top 10 LLM06:2025", "EU AI Act Art. 14"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "LLM-05-Q03",
      "subcatId": "LLM-05",
      "domainId": "LLM",
      "questionText": "Existe limite de ações que um agente de IA pode executar em sequência sem supervisão?",
      "expectedEvidence": "Limites de loop configurados, timeout de sessões agênticas, logs de intervenção",
      "imperativeChecks": "Testar comportamento quando limites são atingidos",
      "riskSummary": "Agentes sem limites podem entrar em loops destrutivos ou consumir recursos",
      "frameworks": ["OWASP LLM Top 10 LLM06:2025", "OWASP LLM Top 10 LLM10:2025"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-01-Q01",
      "subcatId": "API-01",
      "domainId": "API",
      "questionText": "As APIs verificam autorização a nível de objeto para cada requisição?",
      "expectedEvidence": "Implementação de BOLA prevention, testes de autorização, logs de bloqueio",
      "imperativeChecks": "Testar acesso a objetos de outros usuários alterando IDs na requisição",
      "riskSummary": "Falha em BOLA permite acesso a dados de qualquer usuário via ID manipulation",
      "frameworks": ["OWASP API Top 10 API1:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-01-Q02",
      "subcatId": "API-01",
      "domainId": "API",
      "questionText": "Existe controle de propriedades sensíveis nos objetos retornados pela API?",
      "expectedEvidence": "Filtragem de campos sensíveis, schemas de resposta definidos, testes",
      "imperativeChecks": "Verificar que campos sensíveis não são expostos em respostas de API",
      "riskSummary": "Exposição de propriedades sensíveis pode vazar dados confidenciais",
      "frameworks": ["OWASP API Top 10 API3:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-01-Q03",
      "subcatId": "API-01",
      "domainId": "API",
      "questionText": "APIs administrativas são protegidas contra acesso de usuários não privilegiados?",
      "expectedEvidence": "Segregação de endpoints admin, verificação de roles, logs de tentativas",
      "imperativeChecks": "Testar acesso a endpoints administrativos com credenciais normais",
      "riskSummary": "Falha em BFLA permite que usuários comuns executem funções de admin",
      "frameworks": ["OWASP API Top 10 API5:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-02-Q01",
      "subcatId": "API-02",
      "domainId": "API",
      "questionText": "As APIs utilizam mecanismos de autenticação robustos (OAuth 2.0, JWT)?",
      "expectedEvidence": "Implementação de autenticação documentada, validação de tokens, expiração",
      "imperativeChecks": "Verificar proteção contra ataques de replay, token theft, brute force",
      "riskSummary": "Autenticação fraca permite impersonação e acesso não autorizado",
      "frameworks": ["OWASP API Top 10 API2:2023", "NIST SP 800-63B"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-02-Q02",
      "subcatId": "API-02",
      "domainId": "API",
      "questionText": "Tokens de API têm tempo de expiração adequado e são rotacionados?",
      "expectedEvidence": "Configuração de TTL de tokens, processo de rotação, revogação implementada",
      "imperativeChecks": "Verificar impossibilidade de uso de tokens expirados ou revogados",
      "riskSummary": "Tokens de longa duração amplificam impacto de comprometimento",
      "frameworks": ["OWASP API Top 10 API2:2023", "ISO 27001 A.9.4"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-03-Q01",
      "subcatId": "API-03",
      "domainId": "API",
      "questionText": "As APIs possuem rate limiting e throttling configurados adequadamente?",
      "expectedEvidence": "Configuração de limites por usuário/IP, alertas de violação, logs",
      "imperativeChecks": "Testar comportamento com volume alto de requisições",
      "riskSummary": "Sem rate limiting, APIs são vulneráveis a DoS e extração de dados",
      "frameworks": ["OWASP API Top 10 API4:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-03-Q02",
      "subcatId": "API-03",
      "domainId": "API",
      "questionText": "Existe monitoramento de custos e alertas para consumo anômalo de APIs de IA?",
      "expectedEvidence": "Dashboard de custos, alertas configurados, limites de orçamento",
      "imperativeChecks": "Verificar tempo de detecção e resposta a consumo anômalo",
      "riskSummary": "Consumo não monitorado pode resultar em custos inesperados significativos",
      "frameworks": ["OWASP LLM Top 10 LLM10:2025", "OWASP API Top 10 API4:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-03-Q03",
      "subcatId": "API-03",
      "domainId": "API",
      "questionText": "Fluxos de negócio sensíveis são protegidos contra automação e abuso?",
      "expectedEvidence": "Controles anti-automação (CAPTCHA, rate limiting por fluxo), detecção de bots",
      "imperativeChecks": "Testar resistência a automação de fluxos críticos",
      "riskSummary": "Automação de fluxos pode causar fraude, scalping ou exaustão de recursos",
      "frameworks": ["OWASP API Top 10 API6:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-04-Q01",
      "subcatId": "API-04",
      "domainId": "API",
      "questionText": "Existe inventário completo de todas as APIs de IA expostas?",
      "expectedEvidence": "Catálogo de APIs com versões, status, responsáveis e consumidores",
      "imperativeChecks": "Verificar processo de descoberta de shadow APIs e atualização do inventário",
      "riskSummary": "APIs não inventariadas são pontos cegos de segurança",
      "frameworks": ["OWASP API Top 10 API9:2023", "CSA AI Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-04-Q02",
      "subcatId": "API-04",
      "domainId": "API",
      "questionText": "APIs de IA estão configuradas seguindo security hardening guidelines?",
      "expectedEvidence": "Baseline de configuração segura, scans de misconfiguration, remediação",
      "imperativeChecks": "Verificar conformidade com OWASP API Security Checklist",
      "riskSummary": "Configurações inseguras expõem dados e funcionalidades",
      "frameworks": ["OWASP API Top 10 API8:2023", "CSA AI Security"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-04-Q03",
      "subcatId": "API-04",
      "domainId": "API",
      "questionText": "APIs que consomem dados de terceiros validam e sanitizam as respostas?",
      "expectedEvidence": "Validação de schema de respostas, sanitização antes de uso, timeout",
      "imperativeChecks": "Verificar tratamento de respostas malformadas ou maliciosas",
      "riskSummary": "Confiança cega em APIs de terceiros pode introduzir vulnerabilidades",
      "frameworks": ["OWASP API Top 10 API10:2023", "OWASP LLM Top 10 LLM03:2025"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "API-04-Q04",
      "subcatId": "API-04",
      "domainId": "API",
      "questionText": "Existe proteção contra SSRF em APIs que fazem requisições a URLs externas?",
      "expectedEvidence": "Validação de URLs, allowlist de destinos, bloqueio de IPs internos",
      "imperativeChecks": "Testar com URLs que apontam para recursos internos (localhost, metadata)",
      "riskSummary": "SSRF permite atacantes acessarem recursos internos via API vulnerável",
      "frameworks": ["OWASP API Top 10 API7:2023"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-01-Q01",
      "subcatId": "CCM-01",
      "domainId": "CCM",
      "questionText": "Existe programa formal de auditoria e garantia de conformidade para ambientes cloud de IA?",
      "expectedEvidence": "Plano de auditoria, relatórios de conformidade, certificações (SOC 2, ISO 27001)",
      "imperativeChecks": "Verificar frequência de auditorias, cobertura e tratamento de findings",
      "riskSummary": "Sem auditoria formal, gaps de conformidade não são identificados",
      "frameworks": ["CSA CCM A&A-01", "CSA CCM A&A-02", "ISO 27001 9.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "CCM-01-Q02",
      "subcatId": "CCM-01",
      "domainId": "CCM",
      "questionText": "As políticas de segurança cloud são revisadas e aprovadas periodicamente?",
      "expectedEvidence": "Registro de revisões, aprovações formais, controle de versão de políticas",
      "imperativeChecks": "Verificar frequência de revisão e alinhamento com mudanças no ambiente",
      "riskSummary": "Políticas desatualizadas não refletem riscos e controles atuais",
      "frameworks": ["CSA CCM GRC-01", "CSA CCM GRC-02", "ISO 27001 5.2"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "CCM-02-Q01",
      "subcatId": "CCM-02",
      "domainId": "CCM",
      "questionText": "Existe gestão centralizada de identidades para acesso a recursos cloud de IA?",
      "expectedEvidence": "IdP centralizado, SSO implementado, integração com diretório corporativo",
      "imperativeChecks": "Verificar cobertura de todos os serviços cloud de IA e eliminação de contas locais",
      "riskSummary": "Identidades descentralizadas dificultam controle de acesso e offboarding",
      "frameworks": ["CSA CCM IAM-01", "CSA CCM IAM-02", "NIST SP 800-63"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-02-Q02",
      "subcatId": "CCM-02",
      "domainId": "CCM",
      "questionText": "O princípio de menor privilégio é aplicado em recursos cloud de IA?",
      "expectedEvidence": "Políticas de IAM restritivas, revisões periódicas de permissões, just-in-time access",
      "imperativeChecks": "Verificar ausência de permissões excessivas e wildcards em políticas",
      "riskSummary": "Permissões excessivas amplificam impacto de credenciais comprometidas",
      "frameworks": ["CSA CCM IAM-04", "CSA CCM IAM-09", "NIST SP 800-53 AC-6"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-02-Q03",
      "subcatId": "CCM-02",
      "domainId": "CCM",
      "questionText": "Credenciais e secrets para serviços de IA são gerenciados de forma segura?",
      "expectedEvidence": "Secrets manager utilizado, rotação automática, ausência de credenciais hardcoded",
      "imperativeChecks": "Verificar que API keys e tokens não estão expostos em código ou logs",
      "riskSummary": "Credenciais mal gerenciadas são facilmente comprometidas",
      "frameworks": ["CSA CCM IAM-14", "CSA CCM IAM-15", "NIST SP 800-53 IA-5"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-03-Q01",
      "subcatId": "CCM-03",
      "domainId": "CCM",
      "questionText": "Os dados de IA são criptografados em repouso em todos os serviços cloud?",
      "expectedEvidence": "Encryption at rest habilitado, gestão de chaves documentada, KMS utilizado",
      "imperativeChecks": "Verificar cobertura de todos os datastores (S3, databases, model storage)",
      "riskSummary": "Dados não criptografados podem ser expostos em caso de acesso não autorizado",
      "frameworks": ["CSA CCM DSP-01", "CSA CCM DSP-02", "ISO 27001 A.8.24"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-03-Q02",
      "subcatId": "CCM-03",
      "domainId": "CCM",
      "questionText": "Os dados de IA são criptografados em trânsito?",
      "expectedEvidence": "TLS 1.2+ obrigatório, certificados válidos, HSTS habilitado",
      "imperativeChecks": "Verificar que comunicação entre componentes de IA usa criptografia",
      "riskSummary": "Dados em trânsito não criptografados podem ser interceptados",
      "frameworks": ["CSA CCM DSP-03", "CSA CCM DSP-04", "ISO 27001 A.8.24"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-03-Q03",
      "subcatId": "CCM-03",
      "domainId": "CCM",
      "questionText": "Existe classificação de dados aplicada a datasets e modelos de IA em cloud?",
      "expectedEvidence": "Tags de classificação aplicadas, políticas baseadas em classificação",
      "imperativeChecks": "Verificar que dados sensíveis têm controles adicionais aplicados",
      "riskSummary": "Dados não classificados podem não receber proteção adequada",
      "frameworks": ["CSA CCM DSP-05", "CSA CCM DSP-08", "ISO 27001 A.5.12"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "CCM-04-Q01",
      "subcatId": "CCM-04",
      "domainId": "CCM",
      "questionText": "Existe plano de continuidade de negócios para serviços de IA em cloud?",
      "expectedEvidence": "BCP documentado, RTOs/RPOs definidos, testes periódicos realizados",
      "imperativeChecks": "Verificar cobertura de serviços críticos de IA e capacidade de recuperação",
      "riskSummary": "Sem BCP, interrupções em serviços de IA podem impactar operações críticas",
      "frameworks": ["CSA CCM BCR-01", "CSA CCM BCR-02", "ISO 22301"],
      "ownershipType": "GRC"
    },
    {
      "questionId": "CCM-04-Q02",
      "subcatId": "CCM-04",
      "domainId": "CCM",
      "questionText": "Backups de modelos e datasets de IA são realizados e testados regularmente?",
      "expectedEvidence": "Política de backup, testes de restore, armazenamento em região separada",
      "imperativeChecks": "Verificar frequência de backups, retenção e capacidade de restore",
      "riskSummary": "Sem backups testados, perda de dados de IA pode ser irrecuperável",
      "frameworks": ["CSA CCM BCR-11", "CSA CCM BCR-08", "ISO 27001 A.8.13"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-05-Q01",
      "subcatId": "CCM-05",
      "domainId": "CCM",
      "questionText": "Existe logging centralizado para todos os serviços cloud de IA?",
      "expectedEvidence": "SIEM ou log aggregator configurado, logs de todos os serviços coletados",
      "imperativeChecks": "Verificar cobertura de logs de acesso, API calls e atividades administrativas",
      "riskSummary": "Logs descentralizados dificultam detecção e investigação de incidentes",
      "frameworks": ["CSA CCM LOG-01", "CSA CCM LOG-03", "NIST SP 800-53 AU-6"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-05-Q02",
      "subcatId": "CCM-05",
      "domainId": "CCM",
      "questionText": "Os logs de serviços de IA são retidos pelo período adequado e protegidos contra adulteração?",
      "expectedEvidence": "Política de retenção, imutabilidade de logs, controle de acesso a logs",
      "imperativeChecks": "Verificar período de retenção e impossibilidade de alteração de logs",
      "riskSummary": "Logs adulteráveis ou com retenção curta comprometem investigações",
      "frameworks": ["CSA CCM LOG-05", "CSA CCM LOG-09", "ISO 27001 A.8.15"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-06-Q01",
      "subcatId": "CCM-06",
      "domainId": "CCM",
      "questionText": "Existe processo de gestão de vulnerabilidades para infraestrutura cloud de IA?",
      "expectedEvidence": "Scans de vulnerabilidade regulares, processo de remediação, métricas de MTTR",
      "imperativeChecks": "Verificar cobertura de VMs, containers e serviços gerenciados",
      "riskSummary": "Vulnerabilidades não detectadas e remediadas são exploradas por atacantes",
      "frameworks": ["CSA CCM TVM-01", "CSA CCM TVM-02", "NIST SP 800-53 RA-5"],
      "ownershipType": "Engineering"
    },
    {
      "questionId": "CCM-06-Q02",
      "subcatId": "CCM-06",
      "domainId": "CCM",
      "questionText": "Existe processo de gestão de mudanças para infraestrutura de IA em cloud?",
      "expectedEvidence": "Processo de change management, aprovações formais, rollback documentado",
      "imperativeChecks": "Verificar que mudanças passam por aprovação e são rastreáveis",
      "riskSummary": "Mudanças não controladas podem introduzir vulnerabilidades ou indisponibilidade",
      "frameworks": ["CSA CCM CCC-01", "CSA CCM CCC-02", "ISO 27001 A.8.32"],
      "ownershipType": "Engineering"
    }
  ]
}
